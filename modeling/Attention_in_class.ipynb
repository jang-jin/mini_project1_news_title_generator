{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_in_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1k6arUwlI4AafmZ0NFP0-QsZsDKNcwuCf",
      "authorship_tag": "ABX9TyNkt26Wyj2hcgbdQ2AwqJJ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jang-jin/mini_project1_news_title_generator/blob/master/modeling/Attention_in_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXJttWJ9rHgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "499ca323-3e74-486f-dbd5-9c76a9ba296b"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/AI-school/로테이션 수업 자료/NLP/project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/AI-school/로테이션 수업 자료/NLP/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqT3sQ_mreCB",
        "colab_type": "text"
      },
      "source": [
        "# Library import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-u6BLHPrc8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDEtqU_ZrzLL",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jcu63lgryt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "3b15ba16-53b5-4ec8-c3ab-08ecd489caa8"
      },
      "source": [
        "thesciencetimes = pd.read_csv(\"./p_thesciencetimes.csv\", header=None)\n",
        "print(thesciencetimes.shape)\n",
        "kbsnews = pd.read_csv(\"./p_kbsnews.csv\", header=None)\n",
        "print(kbsnews.shape)\n",
        "news_dataset = pd.concat([thesciencetimes, kbsnews])\n",
        "print(news_dataset.shape)\n",
        "news_dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15328, 3)\n",
            "(10861, 3)\n",
            "(26189, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20200826</td>\n",
              "      <td>미국 최초로 GM 모기 살포 실험</td>\n",
              "      <td>미국 남부, 플로리다 주에 길이 약 240km의 산호초 군도가 있다. 플로리다키스 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20200826</td>\n",
              "      <td>공룡도 척추 디스크로 고생했다</td>\n",
              "      <td>척추 디스크는 현대인에게서 가장 많이 발생하는 질환 중 하나다. 국민건강보험공단 등...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20200826</td>\n",
              "      <td>투명 고분자 물질 레이저로 초고속 가공하는 기술 개발</td>\n",
              "      <td>한국연구재단은 서울대 고승환·전누리 교수 연구팀이 투명 물질인 ‘폴리디메틸실록산'(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20200825</td>\n",
              "      <td>기초지원연, 물속 중금속 흡착 철산화물 나노입자 섬유 개발</td>\n",
              "      <td>한국기초과학지원연구원은 박종배 박사 연구팀이 물속 중금속을 흡착할 수 있는 철산화물...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20200824</td>\n",
              "      <td>산업부, 중기 개발한 소재부품장비 양산 위한 성능평가 지원</td>\n",
              "      <td>산업통상자원부는 ‘2020년도 소재·부품·장비(소부장) 양산 성능평가 지원사업’을 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0  ...                                                  2\n",
              "0  20200826  ...  미국 남부, 플로리다 주에 길이 약 240km의 산호초 군도가 있다. 플로리다키스 ...\n",
              "1  20200826  ...  척추 디스크는 현대인에게서 가장 많이 발생하는 질환 중 하나다. 국민건강보험공단 등...\n",
              "2  20200826  ...  한국연구재단은 서울대 고승환·전누리 교수 연구팀이 투명 물질인 ‘폴리디메틸실록산'(...\n",
              "3  20200825  ...  한국기초과학지원연구원은 박종배 박사 연구팀이 물속 중금속을 흡착할 수 있는 철산화물...\n",
              "4  20200824  ...  산업통상자원부는 ‘2020년도 소재·부품·장비(소부장) 양산 성능평가 지원사업’을 ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-sIyLuQuDo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_dataset = news_dataset.sample(frac=1, random_state=13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoWMsVagsFr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "fbc65e20-c275-4b3e-e6de-f1b02c534613"
      },
      "source": [
        "news_dataset[1] = news_dataset[1].str.replace(\"[^\\w]\", \" \")\n",
        "news_dataset[2] = news_dataset[2].str.replace(\"[^\\w]\", \" \")\n",
        "news_dataset[1] = news_dataset[1].replace(\"\", np.nan)\n",
        "news_dataset[2] = news_dataset[2].replace(\"\", np.nan)\n",
        "news_dataset = news_dataset.dropna(how='any')\n",
        "print(news_dataset.shape)\n",
        "news_dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26189, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5565</th>\n",
              "      <td>20160127</td>\n",
              "      <td>제조업  차이나한파  주의보 IT마저 흔들</td>\n",
              "      <td>대한상공회의소가 최근 10여개 업종단체와 공동으로 실시한  2016년 산업 기상도 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4464</th>\n",
              "      <td>20130115</td>\n",
              "      <td>파종에서 재배  수확까지  로봇이 농사꾼</td>\n",
              "      <td>로봇이 위기의 농업을 살릴 구세주로 떠오르고 있다  사람이 파종하는 것보다 10배 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13828</th>\n",
              "      <td>20170405</td>\n",
              "      <td>AI와 융합한 CCTV의 진화</td>\n",
              "      <td>지난해 10월 일본 프로축구 J리그 결승전이 열린 사이타나 스타디움에서는 좀처럼 보...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1567</th>\n",
              "      <td>20190207</td>\n",
              "      <td>고품질 흑연 제조법 개발 성공</td>\n",
              "      <td>기초과학연구원 IBS 은 로드니 루오프 다차원 탄소재료 연구단장 울산과학기술원 자연...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6572</th>\n",
              "      <td>20170313</td>\n",
              "      <td>VR National Parks</td>\n",
              "      <td>If it s difficult for you to take the time to ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0  ...                                                  2\n",
              "5565   20160127  ...  대한상공회의소가 최근 10여개 업종단체와 공동으로 실시한  2016년 산업 기상도 ...\n",
              "4464   20130115  ...  로봇이 위기의 농업을 살릴 구세주로 떠오르고 있다  사람이 파종하는 것보다 10배 ...\n",
              "13828  20170405  ...  지난해 10월 일본 프로축구 J리그 결승전이 열린 사이타나 스타디움에서는 좀처럼 보...\n",
              "1567   20190207  ...  기초과학연구원 IBS 은 로드니 루오프 다차원 탄소재료 연구단장 울산과학기술원 자연...\n",
              "6572   20170313  ...  If it s difficult for you to take the time to ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ6JUJywsgTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "438dde95-f3e4-4ff3-ef99-01dbe361523f"
      },
      "source": [
        "encoder_input, decoder_input, decoder_output = [], [], []\n",
        "\n",
        "for stc in news_dataset[2]:\n",
        "    encoder_input.append(stc.split())\n",
        "\n",
        "# 스타트 뒤에 띄어쓰기\n",
        "for stc in news_dataset[1]:\n",
        "    decoder_input.append((\"<start> \"+stc).split())\n",
        "\n",
        "for stc in news_dataset[1]:\n",
        "    decoder_output.append((stc+\" <end>\").split())\n",
        "\n",
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['대한상공회의소가', '최근', '10여개', '업종단체와', '공동으로', '실시한', '2016년', '산업', '기상도', '조사', '결과를', '발표했다', '그', '결과', '그동안', '그나마', '괜찮은', '실적을', '보였던', '전자', 'IT업종이', '대표적인', '흐림', '업종이', '된', '것으로', '드러났다', '스마트폰', '시장이', '성숙기에', '접어들면서', '올해', '성장률은', '5년', '만에', '처음으로', '한자릿수인', '7', '대로', '떨어질', '것으로', '전망된다', '중국의', '공격적인', '생산과', '투자가', '가장', '큰', '위협이다', '한중', '간', '제살깎기', '경쟁이', '지속하는', '철강도', '여전히', '흐림', '전망이다', '중국', '업체들은', '작년보다', '29', '싼', '가격으로', '물량을', '쏟아내고', '있다', '우리나라에서도', '중국산', '점유율이', '40', '에', '이른다', '그나마', '건설경기', '호조에', '따른', '철근', '수요', '증가세', '올해부터', '공공건설에', '시행되는', '자국산', '우선', '구매제도', '가', '단비가', '될', '것으로', '보인다', '자동차', '업종', '역시', '흐림', '전망이다', '지난해', '개별소비세', '인하로', '사상최대치', '180만대', '를', '기록했던', '내수판매는', '올해', '3', '대의', '감소세를', '기록할', '것으로', '전망된다', '신흥국', '수출도', '신흥국', '통화', '약세로', '부진을', '면치', '못할', '것으로', '보인다', '중국', '경기', '둔화에', '엔저', '低', '까지', '겹치면서', '기계업종도', '흐림', '으로', '전망됐다', '지난해', '상반기만', '해도', '북미지역에서', '예상회의', '호실적을', '거뒀지만', '올해', '중국', '부동산경기', '침체와', '중국', '일본과의', '경쟁', '심화로', '쉽지', '않을', '전망이다', '석유', '의류', '업종의', '예보도', '흐림', '이다', '중국', '수요는', '크게', '감소한', '반면', '중국과', '인도의', '생산', '증대로', '30', '이상', '과잉공급이', '이뤄지고', '있다', '다만', '한', '미', 'FTA', '5년차로', '기존', '2', '였던', '관세가', '철폐된다는', '점이', '긍정적이다', '사상', '초유의', '어닝쇼크를', '겪은', '조선', '업종에는', '흐림을', '넘어', '아예', '눈', '이', '내릴', '것으로', '예보됐다', '설비', '과잉과', '저유가로', '올해', '수주량도', '전년보다', '27', '감소할', '전망이다', '통상', '국제유가가', '배럴당', '60달러는', '돼야', '해양플랜트의', '의미', '있는', '수요개선이', '나타나는데', '지금은', '30달러', '수준이다', '잦은', '설계', '변경과', '공기', '지연까지', '온통', '악재가', '널려', '있다', '그나마', '건설업종은', '구름', '조금', '으로', '예보됐다', '작년의', '호조가', '올해', '상반기까지는', '유지될', '것으로', '보이지만', '하반기부터의', '전망은', '불투명하다', '정유', '유화', '업종은', '견고한', '소비', '덕에', '구름이', '조금', '낀', '날씨가', '될', '것으로', '예상된다', '제조업에서', '중국의', '굴기', '倔起', '가', '본격화되면서', '국내', '업체의', '입지가', '크게', '위협받는', '한', '해가', '될', '수도', '있다는', '게', '대한상의의', '전망이다', '전수봉', '대한상의', '경제조사본부장은', '중국이', '차이나', '인사이드', '로', '주요', '제조업을', '자급자족하며', '자국', '내', '초과공급', '물량을', '낮은', '가격으로', '수출', '밀어내기를', '하고', '있다', '며', '차이나', '한파를', '극복하기', '위해', '노력해야', '한다고', '강조했다'], ['로봇이', '위기의', '농업을', '살릴', '구세주로', '떠오르고', '있다', '사람이', '파종하는', '것보다', '10배', '빠른', '자동파종기', '사막이나', '빌딩에서', '채소를', '재배하는', '식물공장', '등', '농업에', '로봇기술이', '접목되면서', '로봇이', '농사짓는', '상상이', '현실이', '되고', '있다', '경기도농업기원술은', '지난', '2010년', '10월', '28일', '국내', '최초로', '로봇을', '이용한', '식물', '자동생산', '시스템을', '갖춘', '빌딩형', '식물공장을', '선보였다', '식물공장에서는', '로봇이', '4ｍ', '길이의', '레일을', '따라', '이동하며', '상추와', '허브식물에', '영양액을', '준다', '또', '가로', '60', '세로', '80', '크기에', '10', '무게의', '재배판을', '1단에서부터', '10단까지', '높게', '쌓는', '일도', '한다', '이', '재패판은', '식물의', '자라는', '논', '밭과', '같은', '역할을', '한다', '사람이', '사다리를', '타고', '올라', '옮겨야', '하는', '어려운', '일을', '로봇이', '혼자', '알아서', '척척', '해낸다', '로봇이', '무거운', '재배판을', '자동으로', '옮기기', '때문에', '20', '30층', '다단재배도', '가능하다', '수백', '나', '되는', '농사짓는', '땅을', '로봇이', '혼자', '관리하는', '셈이다', '경기농기원은', '재배판이동', '로봇에', '이어', '지난해', '12월', '말', '사람이', '파종하는', '것보다', '10배', '빠른', '자동파종로봇을', '한', '중소업체와', '공동으로', '개발하는', '데', '성공했다', '식물공장용으로', '개발된', '이', '파종로봇은', '사람이', '20분', '걸리는', '파종작업을', '2분', '만에', '해내는', '능력을', '갖췄다', '인력대비', '효율이', '10배나', '된다', '파종로봇', '재배용', '로봇을', '확보한', '경기농기원은', '올해', '말까지', '수확용', '로봇', '개발을', '완료할', '계획이다', '이', '경우', '로봇이', '파종', '재배', '수확까지', '식물재배의', '모든', '과정을', '담당할', '수', '있게', '된다', '경기농기원이', '확보한', '이런', '농업용', '로봇기술은', '스마트', '식물공장의', '카타르', '수출로', '결실을', '보기', '시작했다', '경기도', '경기농기원', '카타르는', '지난', '8일', '스마트', '식물공장', '공동개발과', '보급을', '주요', '내용으로', '하는', '업무협약을', '체결했다', '이에', '따라', '경기농기원이', '개발한', '식물공장이', '사막의', '나라', '중동에', '진출하게', '된', '것이다', '식물공장', '1개당', '100억원의', '시설투자비가', '소요되므로', '최소', '10조', '규모의', '중동시장을', '확보하게', '될', '것으로', '경기농기원은', '기대하고', '있다', '로봇을', '활용한', '첨단농업이', '나아갈', '방향과', '그', '가능성을', '제시했다는', '데', '의미가', '있다', '경기농기원은', '로봇을', '활용한', '농업이', '기후변화', '등으로', '말미암은', '식량위기에', '대처하고', '위기의', '농업을', '살릴', '대안이', '될', '것으로', '전망하면서', '정부와', '지자체의', '적극적인', '지원을', '요구했다', '경기농기원', '미래농업팀', '이상우', '49', '박사는', '로봇을', '이용한', '첨단', '농업기술이', '아직', '걸음마', '단계에', '있지만', '조만간', '선진국', '일본을', '앞지를', '수', '있을', '것으로', '기대한다', '면서', '그럴려면', '국가적', '차원의', '기술개발과', '연구가', '확대될', '필요가', '있다', '고', '말했다'], ['지난해', '10월', '일본', '프로축구', 'J리그', '결승전이', '열린', '사이타나', '스타디움에서는', '좀처럼', '보기', '힘든', '희귀한', '광경이', '연출됐다', '관객들이', '티켓을', '내고', '입장하는', '대신', '경기장의', '입장', '게이트에', '설치된', '감시카메라에', '자신의', '얼굴을', '슬쩍', '비추는', '것으로', '본인', '확인이', '이루어진', '것', '이처럼', '게이트를', '통과한', '관객들은', '입장', '후에', '자신의', '얼굴', '사진이', '들어간', '입장권을', '기념품으로', '받았다', '즉', '관객들의', '얼굴이', '티켓', '기능을', '대체했으며', '입장', '후', '받는', '종이', '티켓은', '단순한', '기념품이었던', '것이다', '캐논과', 'NEC가', '개발한', '이', '기술의', '원리는', '단순하다', 'CCTV에', '얼굴인식이라는', '새로운', '기술을', '융합한', '것', '관객이', '미리', '얼굴', '사진을', '등록해놓으면', '관객의', '얼굴', '자체가', '티켓으로', '인식된다', '원리는', '단순하지만', '이', '기술은', '매우', '다양한', '장점을', '지닌다', '많은', '사람이', '일일이', '게이트를', '통과하면서', '장시간', '기다려야', '하는', '불편함을', '해소할', '수', '있을', '뿐만', '아니라', '티켓', '사재기를', '방지할', '수', '있다', '또한', '음식점에서', '단골손님을', '식별하는', '등의', '비즈니스용으로도', '활용할', '수', '있다', '감시용으로만', '사용되는', 'CCTV가', '최근에', '개발된', '신기술과', '융합되면서', '그', '용도가', '점차', '확대되고', '있다', '대표적인', '것이', '인공지능', 'AI', '과의', '융합이다', 'CCTV가', '지능을', '가지게', '되면', '단순', '행동', '감지에서', '벗어나', '객체를', '추적해', '행위를', '판단할', '수', '있게', '된다', '단순히', '사람의', '눈을', '대신하던', 'CCTV가', '사람의', '두뇌를', '대신하는', '형태로', '진화하고', '있는', '셈이다', '특정', '인물의', '행동을', '사전에', '예측하는', 'CCTV', '인공지능을', '장착한', 'CCTV는', '범죄', '현장에서', '이상', '행동을', '하는', '사람을', '선별하고', '범인을', '추적하거나', '도주', '방향을', '예측해', '통합관제센터로', '통보할', '수', '있다', '또', '수상한', '사람의', '행동', '패턴에', '따라', '지속적인', '추적이나', '감시를', '수행하고', '차량번호', '및', '사람', '얼굴', '등을', '인식해', '관련', '정보를', '분석해', '제공할', '수', '있다', '한국전자통신연구원', 'ETRI', '에서는', 'CCTV', '등의', '영상', '데이터를', '활용해', '특정', '인물이', '어떤', '행동을', '할지를', '사전에', '예측하는', '영상분석', '기술을', '연구', '중인', '것으로', '알려져', '있다', '인공지능', 'CCTV는', '범인', '추적뿐만', '아니라', '자연재해를', '예측하는', '데', '사용할', '수도', '있다', '장마철이나', '국지성', '집중호우', '때', '홍수로', '범람하는', '하천의', '수위를', '감지하는', '것은', '물론', '산이나', '도로', '등의', '붕괴', '예측', '등', '다양한', '분야에', '적용될', '수', '있기', '때문이다', '대한무역투자진흥공사', 'KORTA', '나고야무역관에', '의하면', '일본', '미쓰비시전기는', 'CCTV에', '인공지능', '기술을', '도입해', '공공장소에서', '휘발유', '등', '인화물질', '및', '위험물을', '소지한', '사람을', '자동으로', '찾아내는', '기술을', '개발', '중인', '것으로', '밝혀졌다', '미쓰비시전기의', '니시무라', '상무는', '인공지능의', '진화로', '감시카메라를', '이용한', '영상', '해석', '기술의', '발전은', '가속화될', '것', '이라고', '주장했다', 'CCTV에', '빅데이터', '기술이', '결합되면', '더욱', '다양한', '정보처리가', '가능해진다', '영상에', '찍히는', '사람의', '나이와', '성별까지', '분석이', '가능한', '것은', '물론', '날씨를', '판별할', '수도', '있는', '것', '기상청에서는', 'CCTV', '영상에', '빅데이터', '기술을', '활용해서', '비', '눈', '안개', '등', '날씨를', '판별하는', '기술을', '개발했다', '사물인터넷', 'IoT', '이', '기술이', '결합되면', 'CCTV가', '주변', '기기들과', '폭넓게', '연결돼', '통합', '관리', '시스템의', '구축이', '가능해진다', '슈퍼마켓을', '예로', '들면', 'CCTV가', '출입문', '센서', '계산대', '난방시설', '창고', '등과', '연결됨으로써', '고객의', '얼굴', '인식', '도난', '등의', '특정', '동작', '감시', '방문', '고객수', '분석', '피플', '카운팅', '등의', '업무를', '척척', '해낼', '수', '있다', '이', '같은', '기술은', 'CCTV의', '용도를', '마케팅', '수단이나', '공장의', '생산효율화', '등으로', '변모시킬', '수', '있다', 'CCTV를', '통해', '취득한', '정보를', '바탕으로', '소비자의', '행동을', '분석할', '경우', '마케팅', '자료를', '활용할', '수', '있으며', '제조공장', '내', '작업자', '움직임을', '해석하면', '생산', '효율성', '증가를', '위한', '자료로', '사용할', '수', '있기', '때문이다', '위에서', '예로', '든', '인공지능과', '빅데이터', '사물인터넷', '등은', '모두', '4차', '산업혁명을', '견인하는', '핵심', '기술로', '꼽히는', '분야다', '따라서', 'CCTV의', '진화가', '4차', '산업혁명의', '핵심', '분야', '중', '하나로', '자리매김할', '것이라는', '전망까지', '나오고', '있다', '카메라', '제조사들도', 'CCTV', '기술', '개발에', '참여', 'CCTV의', '진화는', '전통적인', '카메라', '제조사들까지', '움직이게', '하고', '있다', '기존', '카메라', '제조사의', '대다수는', '감시카메라를', '전문으로', '취급하지', '않지만', '기존에', '보유한', '전자기술과', '일반', '카메라', '기술을', '응용함으로써', '스마트한', '감시', '카메라', '개발이', '활발해지고', '있는', '것', '예를', '들면', '파나소닉은', '경비원에게', '장착', '가능한', '웨어러블', '카메라와', '감시', '카메라를', '연계한', '방범', '시스템을', '개발했으며', '소니는', '복수의', '카메라로', '대상을', '추적해', '저해상도의', '광역', '감시', '카메라로도', '사람을', '식별하고', '인증하는', '일까지', '가능한', '기술을', '개발했다', '한편', '캐논은', '감시', '카메라', '분야에서', '세계', '최고의', '기술을', '가진', '스웨덴의', '액시스', 'Axcis', '사를', '28억', '달러에', '인수했다', '2015년에', '이루어진', '액시스의', '인수는', '캐논', '창립', '이후', '최대', '기업', '인수', '합병', 'M', 'A', '으로', '주목을', '끌었다', '액시스는', '네트워크', '감시', '카메라', '솔루션을', '취급하는', '업체로', 'CCTV', '카메라를', '제어하는', '소프트웨어를', '개발해', '공급하는', '회사다', '네트워크', '카메라란', '디지털', '버전의', 'CCTV라고', '할', '수', '있다', '기존', 'CCTV가', '유선으로', '연결된', '폐쇄회로', '기기였다면', '네크워크', '카메라는', '영상신호를', '디지털화해', '통신으로', '보내는', '것이', '차이점이다', '캐논이', '액시스를', '인수한', '것은', '성장', '가능성이', '높은', '산업으로', '전환하기', '위해서인데', '현재', '전', '세계', 'CCTV', '시장은', '네트워크', '카메라로', '재편되고', '있는', '상황이다']]\n",
            "[['<start>', '제조업', '차이나한파', '주의보', 'IT마저', '흔들'], ['<start>', '파종에서', '재배', '수확까지', '로봇이', '농사꾼'], ['<start>', 'AI와', '융합한', 'CCTV의', '진화']]\n",
            "[['제조업', '차이나한파', '주의보', 'IT마저', '흔들', '<end>'], ['파종에서', '재배', '수확까지', '로봇이', '농사꾼', '<end>'], ['AI와', '융합한', 'CCTV의', '진화', '<end>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3lvBkT8svyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "17ded093-551d-481a-a8ca-af2c621751fd"
      },
      "source": [
        "tokenizer_en = Tokenizer(50000)\n",
        "tokenizer_en.fit_on_texts(encoder_input)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(encoder_input)\n",
        "\n",
        "tokenizer_de = Tokenizer(50000)\n",
        "tokenizer_de.fit_on_texts(decoder_input)\n",
        "tokenizer_de.fit_on_texts(decoder_output)\n",
        "decoder_input = tokenizer_de.texts_to_sequences(decoder_input)\n",
        "decoder_output = tokenizer_de.texts_to_sequences(decoder_output)\n",
        "\n",
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[47, 32930, 810, 2320, 1366, 538, 750, 188, 235, 12, 60, 172, 8619, 29391, 12073, 15431, 869, 512, 205, 5, 1639, 308, 2092, 16765, 186, 1108, 506, 349, 483, 2593, 3645, 5, 3100, 753, 8086, 8755, 4033, 25, 36, 37685, 283, 2371, 28616, 790, 719, 197, 8969, 28617, 4499, 10428, 8886, 26500, 2, 6259, 14458, 13307, 841, 43, 4236, 8619, 365, 5164, 5132, 21013, 635, 66, 72, 5, 240, 449, 48181, 153, 719, 150, 41, 34013, 186, 183, 4120, 36373, 12596, 5, 3100, 31942, 9687, 3072, 5, 240, 197, 1490, 653, 265, 20245, 150, 577, 186, 197, 197, 3376, 993, 701, 719, 4500, 8409, 456, 197, 16064, 144, 5994, 405, 3752, 8202, 778, 594, 96, 3590, 2, 598, 13, 300, 122, 125, 27159, 1143, 2139, 31040, 5738, 11110, 1548, 2190, 1482, 4, 3022, 5, 6450, 186, 16766, 4101, 14284, 719, 4015, 7494, 3526, 3, 14123, 1467, 2963, 4702, 2286, 870, 15025, 44063, 2, 8619, 3060, 736, 265, 186, 13455, 5, 3835, 22766, 46015, 19535, 5215, 19536, 1613, 736, 8031, 1989, 72, 5, 1250, 753, 66, 44064, 71, 8255, 36374, 144, 13, 2554, 72, 169, 35, 203, 719, 1999, 18605, 120, 206, 7747, 246, 26500, 341, 8886, 3820, 110, 2, 75, 18605, 3377, 14, 16514, 563, 259], [779, 30192, 21014, 16767, 5594, 2, 251, 1204, 2753, 370, 44065, 8256, 17238, 22312, 6, 25267, 44066, 779, 17239, 5669, 286, 2, 29, 1119, 1101, 1568, 71, 304, 814, 236, 1291, 373, 1569, 2388, 779, 44067, 5535, 46016, 54, 16768, 1497, 40, 6225, 1180, 7036, 1046, 4458, 359, 11681, 740, 15201, 6138, 38, 4, 1986, 4082, 9, 124, 38, 251, 991, 5739, 40578, 42, 473, 725, 779, 3688, 8970, 22313, 779, 2078, 1491, 36375, 16, 482, 503, 1561, 901, 159, 6764, 779, 3688, 3737, 834, 5185, 219, 150, 1090, 716, 251, 1204, 2753, 370, 13, 810, 851, 90, 499, 570, 4, 251, 6692, 1936, 13932, 506, 469, 12597, 1598, 9894, 73, 814, 3200, 186, 4016, 230, 560, 16515, 289, 4, 33, 779, 9527, 102, 248, 15026, 1, 192, 73, 3200, 30, 25863, 255, 14285, 3001, 627, 3455, 29, 1412, 255, 22312, 11306, 206, 11307, 42, 20246, 10142, 98, 54, 148, 17497, 4258, 205, 21, 22312, 1555, 20612, 943, 18303, 72, 5, 788, 2, 814, 648, 14663, 7850, 12, 406, 13606, 90, 1175, 2, 814, 648, 21850, 1869, 293, 42243, 42244, 30192, 21014, 16767, 8887, 72, 5, 48182, 3029, 23228, 3030, 858, 17010, 12878, 78, 814, 236, 387, 237, 19884, 2457, 160, 2837, 6491, 14286, 1, 55, 5, 1650, 500, 8139, 3502, 27160, 191, 5461, 553, 2, 7, 18], [150, 1101, 244, 542, 11308, 3001, 1562, 9609, 44068, 42245, 3085, 490, 21411, 1772, 338, 2506, 21851, 5, 8888, 9985, 1511, 19, 319, 5850, 27879, 21411, 1906, 338, 1508, 7037, 2667, 1146, 196, 39118, 6807, 40579, 174, 21411, 97, 595, 1863, 1518, 21, 148, 4, 638, 4966, 30193, 42246, 28, 83, 11555, 19, 879, 1508, 1109, 1508, 1391, 4966, 4, 279, 56, 58, 1966, 6896, 26, 251, 4553, 16065, 2619, 13308, 42, 9785, 10143, 1, 55, 665, 84, 40579, 7539, 1, 2, 85, 16066, 91, 521, 1, 2, 702, 21015, 2300, 570, 40580, 12, 16769, 861, 6260, 2, 512, 23, 231, 358, 12733, 21015, 7305, 8889, 241, 5244, 2241, 2905, 7387, 5402, 6298, 1, 192, 73, 1295, 199, 1739, 21015, 199, 12879, 14287, 544, 5245, 3, 834, 247, 26501, 1099, 2848, 3197, 7540, 2131, 4945, 29392, 3836, 1915, 96, 1099, 42, 941, 46017, 20613, 1137, 11210, 1, 2, 40, 8257, 199, 2241, 17761, 54, 1967, 18914, 3603, 24, 592, 1508, 67, 5095, 93, 156, 730, 1426, 1, 2, 4858, 3086, 1450, 7540, 91, 757, 328, 501, 247, 16770, 87, 1099, 37686, 2848, 3197, 83, 44, 407, 5, 245, 2, 231, 29392, 32931, 84, 44069, 3197, 90, 352, 169, 2, 10854, 23720, 31, 42247, 48183, 20247, 3430, 32, 152, 31041, 2212, 91, 7086, 1620, 6, 58, 687, 2640, 1, 135, 76, 32932, 1067, 244, 42246, 231, 83, 4744, 44070, 13933, 6, 24, 941, 1491, 4172, 83, 140, 407, 5, 486, 14459, 3294, 236, 757, 17011, 638, 5268, 22767, 19, 53, 656, 42246, 1427, 178, 46018, 141, 58, 7639, 12472, 199, 13148, 2269, 216, 32, 152, 12598, 23229, 169, 3, 19, 7540, 12472, 1427, 83, 13770, 3370, 1482, 20614, 6, 12598, 21412, 83, 417, 987, 1498, 4, 178, 46018, 21015, 646, 5931, 3716, 2700, 1161, 2245, 11309, 7639, 3397, 1522, 21015, 40581, 1103, 34014, 824, 8815, 1508, 2030, 31042, 91, 247, 6492, 3087, 8890, 331, 91, 3558, 22313, 23230, 1, 2, 4, 9, 279, 24688, 3979, 17240, 293, 1, 2, 22768, 8, 31043, 156, 611, 8678, 1099, 2405, 33, 3979, 578, 521, 1, 151, 246, 44071, 1008, 778, 11814, 9610, 52, 9986, 352, 1, 135, 76, 2743, 3397, 3895, 4859, 1427, 987, 964, 111, 915, 9127, 34015, 478, 489, 4516, 7541, 180, 8620, 915, 6100, 478, 345, 50, 859, 44072, 509, 1503, 2, 1225, 7540, 123, 292, 3717, 13309, 2860, 1225, 7691, 110, 2, 122, 1225, 27880, 17762, 24689, 1897, 1690, 2209, 504, 1225, 83, 11682, 3087, 1225, 829, 23231, 3, 19, 510, 1522, 15027, 216, 1032, 7087, 3087, 2412, 13021, 373, 17241, 29393, 26502, 4992, 4967, 7387, 22314, 3087, 941, 28618, 27161, 216, 83, 417, 257, 3087, 1225, 484, 70, 1732, 83, 182, 12473, 4993, 25864, 8679, 1511, 27162, 128, 222, 671, 11451, 17242, 2327, 281, 265, 433, 3177, 1369, 3087, 1225, 8475, 31044, 27163, 7540, 2412, 2759, 5317, 803, 3178, 17498, 1369, 374, 22769, 46, 1, 2, 122, 21015, 48184, 2025, 46019, 6733, 30194, 2146, 23, 13934, 32, 1413, 175, 94, 10062, 35152, 64, 68, 70, 7540, 2668, 1369, 4992, 3, 980]]\n",
            "[[1, 2867, 14549, 668, 14550, 2868], [1, 14551, 1984, 9014, 339, 14552], [1, 6582, 6583, 9015, 134]]\n",
            "[[2867, 14549, 668, 14550, 2868, 2], [14551, 1984, 9014, 339, 14552, 2], [6582, 6583, 9015, 134, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ekE0KGs4b-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "671e7d81-27aa-4cc2-fd6e-2e79776f0ca3"
      },
      "source": [
        "len_en = list(map(len, encoder_input))\n",
        "len_de = list(map(len, decoder_input))\n",
        "\n",
        "plt.hist(len_en, label='en', alpha=0.7)\n",
        "plt.hist(len_de, label='de', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLXs-ZHDs8vB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "0f67fe18-6efd-450f-d559-87ca68ce7a79"
      },
      "source": [
        "print(f\"인코더 데이터 길이 평균 : {np.mean(len_en)}\")\n",
        "print(f\"디코더 데이터 길이 평균 : {np.mean(len_de)}\")\n",
        "print(f\"인코더 데이터 길이 중간값 : {np.median(len_en)}\")\n",
        "print(f\"디코더 데이터 길이 중간값 : {np.median(len_de)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코더 데이터 길이 평균 : 261.1189430677002\n",
            "디코더 데이터 길이 평균 : 6.9282523196762\n",
            "인코더 데이터 길이 중간값 : 180.0\n",
            "디코더 데이터 길이 중간값 : 7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B86ZHi9s9mg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "8518f163-624b-4ae8-bf9e-002abf63c459"
      },
      "source": [
        "# padding=\"post\" : 앞부터 문장, 뒤에 0값을 채우기 위해\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\", maxlen=500)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "decoder_output = pad_sequences(decoder_output, padding=\"post\")\n",
        "\n",
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])\n",
        "print(encoder_input.shape)\n",
        "print(decoder_input.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   47 32930   810 ...     0     0     0]\n",
            " [  779 30192 21014 ...     0     0     0]\n",
            " [  244   542 11308 ...  4992     3   980]]\n",
            "[[    1  2867 14549   668 14550  2868     0     0     0     0     0     0\n",
            "      0     0]\n",
            " [    1 14551  1984  9014   339 14552     0     0     0     0     0     0\n",
            "      0     0]\n",
            " [    1  6582  6583  9015   134     0     0     0     0     0     0     0\n",
            "      0     0]]\n",
            "[[ 2867 14549   668 14550  2868     2     0     0     0     0     0     0\n",
            "      0     0]\n",
            " [14551  1984  9014   339 14552     2     0     0     0     0     0     0\n",
            "      0     0]\n",
            " [ 6582  6583  9015   134     2     0     0     0     0     0     0     0\n",
            "      0     0]]\n",
            "(26189, 500)\n",
            "(26189, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPV_QUuctBrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 나중에 prediction 할 때 사용하기 위함(인덱스로 단어 찾기)\n",
        "de_to_index = tokenizer_de.word_index\n",
        "index_to_de = tokenizer_de.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs_OOfmXtPDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_size = 5000\n",
        "encoder_input_train = encoder_input[:-test_size]\n",
        "decoder_input_train = decoder_input[:-test_size]\n",
        "decoder_output_train = decoder_output[:-test_size]\n",
        "\n",
        "encoder_input_test = encoder_input[-test_size:]\n",
        "decoder_input_test = decoder_input[-test_size:]\n",
        "decoder_output_test = decoder_output[-test_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuyAygO8unKh",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH4vNR96v7zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyperparameter\n",
        "word_embedding = 100\n",
        "LSTM_unit = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RbAniExul4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = Input(shape=(encoder_input.shape[1],))\n",
        "encoder_embed = Embedding(len(tokenizer_en.word_index)+1, word_embedding)(encoder_inputs)\n",
        "encoder_mask = Masking(mask_value=0)(encoder_embed)\n",
        "encoder_outputs, h_state, c_state = LSTM(LSTM_unit, return_state=True, return_sequences=True)(encoder_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1yWuKcSvJTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(decoder_input.shape[1],))\n",
        "decoder_embed = Embedding(len(tokenizer_de.word_index)+1, word_embedding)(decoder_inputs)\n",
        "decoder_mask = Masking(mask_value=0)(decoder_embed)\n",
        "decoder_lstm = LSTM(LSTM_unit, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-GNBwxmvK6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from attention import AttentionLayer\n",
        "\n",
        "attn_layer = AttentionLayer()\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "decoder_concat_input = Concatenate()([decoder_outputs, attn_out])\n",
        "\n",
        "decoder_dense = Dense(len(tokenizer_en.word_index)+1, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_dense(decoder_concat_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQUxOwowtwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "a7ffb757-4d29-414e-e01d-bd687fe86dd4"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 14)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 500, 100)     72525900    input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 14, 100)      3970000     input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking_2 (Masking)             (None, 500, 100)     0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "masking_3 (Masking)             (None, 14, 100)      0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 500, 50), (N 30200       masking_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, 14, 50), (No 30200       masking_3[0][0]                  \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer_1 (AttentionLay ((None, 14, 50), (No 5050        lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 100)      0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 14, 725259)   73251159    concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 149,812,509\n",
            "Trainable params: 149,812,509\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6nfSze1x7Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "model_check = ModelCheckpoint('./seq2seq_news_title.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFeVS_36yCVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e76c3396-62d9-43fe-fd79-e1f367cfe9ac"
      },
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_output_train,\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_output_test),\n",
        "          batch_size=32, epochs=100,\n",
        "          callbacks=[early_stop, model_check])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 5.0202 - acc: 0.5619\n",
            "Epoch 00001: val_acc improved from -inf to 0.57669, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 536s 808ms/step - loss: 5.0202 - acc: 0.5619 - val_loss: 4.5188 - val_acc: 0.5767\n",
            "Epoch 2/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 4.3917 - acc: 0.5784\n",
            "Epoch 00002: val_acc improved from 0.57669 to 0.57813, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 534s 806ms/step - loss: 4.3917 - acc: 0.5784 - val_loss: 4.4299 - val_acc: 0.5781\n",
            "Epoch 3/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 4.3165 - acc: 0.5804\n",
            "Epoch 00003: val_acc improved from 0.57813 to 0.58030, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 528s 796ms/step - loss: 4.3165 - acc: 0.5804 - val_loss: 4.4106 - val_acc: 0.5803\n",
            "Epoch 4/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 4.2501 - acc: 0.5835\n",
            "Epoch 00004: val_acc improved from 0.58030 to 0.58347, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 531s 801ms/step - loss: 4.2501 - acc: 0.5835 - val_loss: 4.3559 - val_acc: 0.5835\n",
            "Epoch 5/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 4.1813 - acc: 0.5862\n",
            "Epoch 00005: val_acc improved from 0.58347 to 0.58439, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 535s 808ms/step - loss: 4.1813 - acc: 0.5862 - val_loss: 4.3346 - val_acc: 0.5844\n",
            "Epoch 6/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 4.1272 - acc: 0.5889\n",
            "Epoch 00006: val_acc improved from 0.58439 to 0.58623, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 535s 807ms/step - loss: 4.1272 - acc: 0.5889 - val_loss: 4.3412 - val_acc: 0.5862\n",
            "Epoch 7/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 4.0829 - acc: 0.5916\n",
            "Epoch 00007: val_acc improved from 0.58623 to 0.58737, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 530s 800ms/step - loss: 4.0829 - acc: 0.5916 - val_loss: 4.3061 - val_acc: 0.5874\n",
            "Epoch 8/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 4.0458 - acc: 0.5943\n",
            "Epoch 00008: val_acc improved from 0.58737 to 0.58863, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 526s 794ms/step - loss: 4.0458 - acc: 0.5943 - val_loss: 4.3007 - val_acc: 0.5886\n",
            "Epoch 9/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 4.0036 - acc: 0.5968\n",
            "Epoch 00009: val_acc improved from 0.58863 to 0.58867, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 528s 796ms/step - loss: 4.0036 - acc: 0.5968 - val_loss: 4.3079 - val_acc: 0.5887\n",
            "Epoch 10/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.9706 - acc: 0.5994\n",
            "Epoch 00010: val_acc improved from 0.58867 to 0.58929, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 528s 797ms/step - loss: 3.9706 - acc: 0.5994 - val_loss: 4.3294 - val_acc: 0.5893\n",
            "Epoch 11/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.9351 - acc: 0.6017\n",
            "Epoch 00011: val_acc improved from 0.58929 to 0.58950, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 524s 790ms/step - loss: 3.9351 - acc: 0.6017 - val_loss: 4.3112 - val_acc: 0.5895\n",
            "Epoch 12/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.8935 - acc: 0.6042\n",
            "Epoch 00012: val_acc did not improve from 0.58950\n",
            "663/663 [==============================] - 524s 791ms/step - loss: 3.8935 - acc: 0.6042 - val_loss: 4.2959 - val_acc: 0.5883\n",
            "Epoch 13/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.8538 - acc: 0.6063\n",
            "Epoch 00013: val_acc improved from 0.58950 to 0.59060, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 529s 798ms/step - loss: 3.8538 - acc: 0.6063 - val_loss: 4.2945 - val_acc: 0.5906\n",
            "Epoch 14/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.8283 - acc: 0.6085\n",
            "Epoch 00014: val_acc did not improve from 0.59060\n",
            "663/663 [==============================] - 519s 782ms/step - loss: 3.8283 - acc: 0.6085 - val_loss: 4.2914 - val_acc: 0.5905\n",
            "Epoch 15/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.8117 - acc: 0.6112\n",
            "Epoch 00015: val_acc did not improve from 0.59060\n",
            "663/663 [==============================] - 514s 775ms/step - loss: 3.8117 - acc: 0.6112 - val_loss: 4.2987 - val_acc: 0.5891\n",
            "Epoch 16/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.7986 - acc: 0.6139\n",
            "Epoch 00016: val_acc did not improve from 0.59060\n",
            "663/663 [==============================] - 510s 769ms/step - loss: 3.7986 - acc: 0.6139 - val_loss: 4.3013 - val_acc: 0.5905\n",
            "Epoch 17/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.7766 - acc: 0.6162\n",
            "Epoch 00017: val_acc did not improve from 0.59060\n",
            "663/663 [==============================] - 509s 768ms/step - loss: 3.7766 - acc: 0.6162 - val_loss: 4.3062 - val_acc: 0.5900\n",
            "Epoch 18/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.7512 - acc: 0.6191\n",
            "Epoch 00018: val_acc improved from 0.59060 to 0.59070, saving model to ./seq2seq_news_title.h5\n",
            "663/663 [==============================] - 522s 788ms/step - loss: 3.7512 - acc: 0.6191 - val_loss: 4.3007 - val_acc: 0.5907\n",
            "Epoch 19/100\n",
            "663/663 [==============================] - ETA: 0s - loss: 3.7259 - acc: 0.6220\n",
            "Epoch 00019: val_acc did not improve from 0.59070\n",
            "663/663 [==============================] - 511s 770ms/step - loss: 3.7259 - acc: 0.6220 - val_loss: 4.3181 - val_acc: 0.5903\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2e84fcd080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLMsxJT8yIyt",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nb1Ska5yKQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, [encoder_outputs, h_state, c_state])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4L6aLKwyKAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_h_state = Input(shape=(LSTM_unit,))\n",
        "encoder_c_state = Input(shape=(LSTM_unit,))\n",
        "\n",
        "pd_decoder_outputs, pd_h_state, pd_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_h_state, encoder_c_state])\n",
        "\n",
        "# 어텐션\n",
        "pd_encoder_outputs = Input(shape=(encoder_input.shape[1], LSTM_unit))\n",
        "pd_attn_out, pd_attn_states = attn_layer([pd_encoder_outputs, pd_decoder_outputs])\n",
        "pd_decoder_concat = Concatenate()([pd_decoder_outputs, pd_attn_out])\n",
        "\n",
        "pd_decoder_softmax_outputs = decoder_dense(pd_decoder_concat)\n",
        "\n",
        "decoder_model = Model([decoder_inputs, pd_encoder_outputs, encoder_h_state, encoder_c_state], [pd_decoder_softmax_outputs, pd_h_state, pd_c_state])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If02WeQJy4Ny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5087c406-f74a-4c37-a563-2270f212f54e"
      },
      "source": [
        "input_stc = input()\n",
        "token_stc = input_stc.replace(\"\\n\",\" \").replace(\" +\", \" \").replace(\"[^\\w]\",\"\").split()\n",
        "encode_stc = tokenizer_en.texts_to_sequences([token_stc])\n",
        "pad_stc = pad_sequences(encode_stc, maxlen=encoder_input.shape[1], padding=\"post\")\n",
        "\n",
        "en_out, en_hidden, en_cell = encoder_model.predict(pad_stc)\n",
        "\n",
        "predicted_seq = np.zeros((1,1))\n",
        "predicted_seq[0,0] = de_to_index[\"<start>\"]\n",
        "\n",
        "decoded_stc = []\n",
        "\n",
        "while True:\n",
        "    output_words, h, c = decoder_model.predict([predicted_seq, en_out, en_hidden, en_cell])\n",
        "\n",
        "    predicted_word = index_to_de[np.argmax(output_words[0,0])]\n",
        "\n",
        "    if predicted_word == \"<end>\":\n",
        "        break\n",
        "    \n",
        "    decoded_stc.append(predicted_word)\n",
        "\n",
        "    predicted_seq = np.zeros((1,1))\n",
        "    predicted_seq[0,0] = np.argmax(output_words[0,0])\n",
        "\n",
        "    en_hidden = h\n",
        "    en_cell = c\n",
        "\n",
        "print(' '.join(decoded_stc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IT서비스 개발인력이 코로나 위협에 내몰리고 있다. 고객사가 마련한 좁은 공간에 모여 프로젝트를 수행할 수밖에 없는 구조적 현실 때문이다. 고객사 배려와 부분 원격지 근무 의무화 등 제도적 보완이 요구된다.  코로나19가 장기화되면서 고객사에 파견된 IT서비스 인력 사이에서 건강 우려가 확산된다.  고객사 시스템을 구축하는 개발자는 프로젝트 기간 동안 고객사가 지정한 장소에서 수개월~수년간 근무한다. 비좁고 밀폐된 임시 장소에서 다수가 근무하기 때문에 코로나 같은 감염병에 취약하다.  A은행 IT시스템을 구축 중인 한 IT서비스 기업 개발자는 “A은행 건물 1층을 활용해 프로젝트를 진행하는데 막바지가 될수록 투입 인원이 늘어난다”면서 “교실 4개 크기 공간에 200명 가까운 인력이 콩나물처럼 모여 근무 중”이라고 말했다.  그는 “임시 공간이다 보니 휴게실이나 회의실 같은 구분이 없어 확진자 1명만 나와도 수백명이 격리에 들어가야 하는 상황”이라며 “조금만 움직여도 몸이 닿을 듯한 거리에서 작업을 하고 있어서 모두의 불안감이 커지고 있다”고 털어놨다.  재택이나 순환 근무를 허용하는 고객사도 있다. 30억~40억원 미만 중소 프로젝트 중에서는 원격개발 방식을 택한 사례도 있다. 그러나 많은 인력이 필요한 중대형 IT프로젝트는 대부분 A은행과 같은 상황에서 진행된다. 규모가 클수록 보안 등 이유로 재택 전환이나 원격지 개발이 어렵기 때문이다.  고객사가 내부 계열사라도 상황은 다르지 않다.  또 다른 IT서비스 기업 관계자는 “내부 계열사라고 해서 납기를 연장해주는 게 아니라서 어쩔 수 없이 출근을 해야 한다”면서 “고객사는 필요하면 필수인력 제외하고 재택을 하라고 하지만 어디까지나 권고일 뿐”이라고 말했다.  IT서비스 기업 인력은 본인이 코로나에 감염될까 걱정한다. 본인으로 인해 중요 프로젝트가 중단되는 것은 더 두려워한다.  파견 인력이 본사 직원에게 느끼는 상실감도 존재한다. 한 대형 IT서비스 기업 본사는 코로나 확산에 따라 재택근무에 돌입했다. 그러나 고객사에 파견된 인력은 고객사 정책을 따라야하기 때문에 소외감을 느낄 수밖에 없다.  이 같은 문제는 고객사가 외주인력이 같은 건물에서 일하기를 원하기 때문에 발생한다. 대면을 바라는 정서상 이유나 업무 효율성, 보안 유지 차원에서 수십년간 지속돼온 방식이다. 금융권의 경우엔 개인정보 유출 방지를 위해 원격지 개발을 허용하지 않는다. 네트워크가 폐쇄망이라 외부 접속이 불가능하다.  투입 인력 수로 사업 단가를 책정하는 '맨먼스' 계약 방식도 개발인력을 고객사에 붙잡아두는 요인이다. 고객사는 특정 등급 이상 개발자 일정 인원이 현장에 상주하기를 요구한다. 공공 분야에서는 2018년부터 헤드카운팅을 금지했지만 민간에서는 효력을 발휘하지 못한다.  프로젝트가 지연됐을 경우 IT서비스 업체가 지는 배상 의무도 한정된 공간에 많은 인력을 투입하게 한다.  IT서비스 업계는 발주자 측에 부분 원격지 근무 등을 통해 개발자 밀집도를 줄이는 방안을 강구해주길 요청했다.  기업은행 관계자는 “외주 개발자도 사용할 수 있도록 재택근무 시스템을 개발 중”이라면서 “감독기관 협조가 필요하겠지만 기술적으로 가능한 기반을 준비할 필요가 있다”고 말했다. 그는 그러나 원격지 개발과 보안에 대한 인식 전환이 선행돼야 할 것이라고 덧붙였다.\n",
            "국내 연구진 5g 시대 온다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi7BJm46aw9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}