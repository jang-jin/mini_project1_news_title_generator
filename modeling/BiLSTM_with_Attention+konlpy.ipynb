{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM with Attention+konlpy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1nnJRpdhczw-S4yvl5IBLRurzxxgrVqfv",
      "authorship_tag": "ABX9TyOCOYWnLZt+rO0zU2BHtqzN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jang-jin/mini_project1_news_title_generator/blob/master/modeling/BiLSTM_with_Attention%2Bkonlpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAos104ThBK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d270f999-430a-4c9a-f659-7826f9ac1222"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/AI-school/로테이션 수업 자료/NLP/project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/AI-school/로테이션 수업 자료/NLP/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqT3sQ_mreCB",
        "colab_type": "text"
      },
      "source": [
        "# Library import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfNSVx29FS6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "fe99f7a2-befd-498f-92ee-0a5e5a427d3c"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 158kB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 57.2MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: tweepy, JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-u6BLHPrc8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from konlpy.tag import Hannanum, Kkma, Komoran, Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Concatenate, Bidirectional, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDEtqU_ZrzLL",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jcu63lgryt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "748988b3-5020-483a-ffb3-75bed55d242b"
      },
      "source": [
        "news_dataset = pd.read_csv(\"./news_dataset.csv\")\n",
        "print(news_dataset.shape)\n",
        "news_dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27322, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>미국 최초로 GM 모기 살포 실험</td>\n",
              "      <td>미국 남부, 플로리다 주에 길이 약 240km의 산호초 군도가 있다. 플로리다키스 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>공룡도 척추 디스크로 고생했다</td>\n",
              "      <td>척추 디스크는 현대인에게서 가장 많이 발생하는 질환 중 하나다. 국민건강보험공단 등...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>투명 고분자 물질 레이저로 초고속 가공하는 기술 개발</td>\n",
              "      <td>한국연구재단은 서울대 고승환·전누리 교수 연구팀이 투명 물질인 ‘폴리디메틸실록산'(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>기초지원연, 물속 중금속 흡착 철산화물 나노입자 섬유 개발</td>\n",
              "      <td>한국기초과학지원연구원은 박종배 박사 연구팀이 물속 중금속을 흡착할 수 있는 철산화물...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>산업부, 중기 개발한 소재부품장비 양산 위한 성능평가 지원</td>\n",
              "      <td>산업통상자원부는 ‘2020년도 소재·부품·장비(소부장) 양산 성능평가 지원사업’을 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              title                                            article\n",
              "0                미국 최초로 GM 모기 살포 실험  미국 남부, 플로리다 주에 길이 약 240km의 산호초 군도가 있다. 플로리다키스 ...\n",
              "1                  공룡도 척추 디스크로 고생했다  척추 디스크는 현대인에게서 가장 많이 발생하는 질환 중 하나다. 국민건강보험공단 등...\n",
              "2     투명 고분자 물질 레이저로 초고속 가공하는 기술 개발  한국연구재단은 서울대 고승환·전누리 교수 연구팀이 투명 물질인 ‘폴리디메틸실록산'(...\n",
              "3  기초지원연, 물속 중금속 흡착 철산화물 나노입자 섬유 개발  한국기초과학지원연구원은 박종배 박사 연구팀이 물속 중금속을 흡착할 수 있는 철산화물...\n",
              "4  산업부, 중기 개발한 소재부품장비 양산 위한 성능평가 지원  산업통상자원부는 ‘2020년도 소재·부품·장비(소부장) 양산 성능평가 지원사업’을 ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-sIyLuQuDo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_dataset = news_dataset.sample(frac=1, random_state=13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoWMsVagsFr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "31fea9f7-92df-4331-91be-632de7a34c6a"
      },
      "source": [
        "news_dataset['title'] = news_dataset['title'].str.replace(\"[^\\w]\", \" \")\n",
        "news_dataset['article'] = news_dataset['article'].str.replace(\"[^\\w]\", \" \")\n",
        "news_dataset['title'] = news_dataset['title'].replace(\"\", np.nan)\n",
        "news_dataset['article'] = news_dataset['article'].replace(\"\", np.nan)\n",
        "news_dataset = news_dataset.dropna(how='any')\n",
        "print(news_dataset.shape)\n",
        "news_dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27321, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23692</th>\n",
              "      <td>Missing People Measure</td>\n",
              "      <td>Families who have lost children or elderly dem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26700</th>\n",
              "      <td>국내 ICT 기업 연구개발비 40조원 돌파</td>\n",
              "      <td>국내 정보통신기술 ICT 기업의 연구개발비가 40조원을 돌파한 것으로 나타났다 과...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19604</th>\n",
              "      <td>주파수 훔쳐 쓰다간 엉뚱한 대형사고 납니다</td>\n",
              "      <td>얼마전 개봉한 영화  나이트 크롤러  감독 댄 길로이 를 아십니까 직장이 없는  루...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9335</th>\n",
              "      <td>크루 드래건   뭐가 달라졌나</td>\n",
              "      <td>지난달 31일 한국 시각  발사된 스페이스X의 유인 우주선  크루 드래건 이 국제우...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18625</th>\n",
              "      <td>미래부  평창 ICT 동계올림픽 추진 TF  출범</td>\n",
              "      <td>오는 2018년 평창 동계올림픽이 성공적으로 개최되도록 정보통신기술을 개발 지원하는...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             title                                            article\n",
              "23692       Missing People Measure  Families who have lost children or elderly dem...\n",
              "26700      국내 ICT 기업 연구개발비 40조원 돌파   국내 정보통신기술 ICT 기업의 연구개발비가 40조원을 돌파한 것으로 나타났다 과...\n",
              "19604      주파수 훔쳐 쓰다간 엉뚱한 대형사고 납니다  얼마전 개봉한 영화  나이트 크롤러  감독 댄 길로이 를 아십니까 직장이 없는  루...\n",
              "9335             크루 드래건   뭐가 달라졌나   지난달 31일 한국 시각  발사된 스페이스X의 유인 우주선  크루 드래건 이 국제우...\n",
              "18625  미래부  평창 ICT 동계올림픽 추진 TF  출범  오는 2018년 평창 동계올림픽이 성공적으로 개최되도록 정보통신기술을 개발 지원하는..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ6JUJywsgTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "aee9f23c-57dd-4aca-e080-4b342c6eeb8b"
      },
      "source": [
        "encoder_input, decoder_input, decoder_output = [], [], []\n",
        "okt = Okt()\n",
        "\n",
        "for stc in news_dataset['article']:\n",
        "    encoder_input.append(okt.morphs(stc, stem=True))\n",
        "\n",
        "# 스타트 뒤에 띄어쓰기\n",
        "for stc in news_dataset['title']:\n",
        "    decoder_input.append([\"<start>\"]+okt.morphs(stc, stem=True))\n",
        "\n",
        "for stc in news_dataset['title']:\n",
        "    decoder_output.append(okt.morphs(stc, stem=True)+[\"<end>\"])\n",
        "\n",
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Families', 'who', 'have', 'lost', 'children', 'or', 'elderly', 'dementia', 'parents', 'suffer', 'from', 'indescribable', 'pain', 'In', 'the', 'case', 'of', 'missing', 'people', 'incidents', 'tracking', 'down', 'their', 'whereabouts', 'in', 'the', 'first', '48', 'hours', 'is', 'crucial', 'in', 'efforts', 'to', 'locate', 'the', 'individuals', 'Korean', 'researchers', 'have', 'joined', 'hands', 'with', 'the', 'police', 'to', 'reduce', 'this', 'golden', 'time', 'window', 'for', 'better', 'chances', 'of', 'finding', 'our', 'loved', 'ones', 'About', '40', 'thousand', 'children', 'and', 'dementia', 'patients', 'go', 'missing', 'every', 'year', 'Luckily', 'in', 'most', 'cases', 'they', 'are', 'reunited', 'with', 'their', 'families', 'Figuring', 'out', 'their', 'travel', 'path', 'is', 'most', 'important', 'in', 'locating', 'missing', 'people', 'Officials', 'must', 'trace', 'the', 'movements', 'of', 'the', 'missing', 'persons', 'during', 'the', 'initial', '48', 'hour', 'period', 'the', 'so', 'called', 'golden', 'time', 'Gang', 'Seong', 'woo', 'Seoul', 'Metropolitan', 'Police', 'Agency', 'Failure', 'to', 'locate', 'the', 'missing', 'in', 'the', 'early', 'stage', 'leads', 'to', 'wider', 'investigation', 'and', 'likely', 'more', 'time', 'spent', 'until', 'the', 'person', 'is', 'found', 'Korean', 'researchers', 'have', 'developed', 'a', 'technology', 'aimed', 'at', 'reducing', 'this', 'critical', 'window', 'of', 'time', 'Various', 'information', 'such', 'as', 'the', 'time', 'and', 'location', 'of', 'disappearance', 'and', 'the', 'person', 's', 'behavioral', 'traits', 'are', 'gathered', 'and', 'put', 'through', 'an', 'analysis', 'by', 'artificial', 'intelligence', 'Using', 'this', 'technology', 'a', 'missing', 'person', 'can', 'be', 'tracked', 'down', 'from', 'numerous', 'images', 'taken', 'by', 'dozens', 'of', 'security', 'cameras', 'And', 'there', 's', 'more', 'Choi', 'Jun', 'won', 'went', 'missing', 'from', 'a', 'playground', 'outside', 'of', 'her', 'home', '18', 'years', 'ago', 'She', 'was', '6', 'at', 'the', 'time', 'and', 'would', 'be', '24', 'this', 'year', 'but', 'the', 'photo', 'on', 'the', 'pamphlet', 'still', 'shows', 'the', 'six', 'year', 'old', 'girl', 'The', 'frontal', 'and', 'even', 'profile', 'image', 'of', 'her', 'current', 'face', 'can', 'be', 'predicted', 'using', 'AI', 'and', '3', 'D', 'reconstruction', 'technologies', 'Kim', 'Ik', 'jae', 'President', 'KIST', 'Center', 'for', 'Imaging', 'Media', 'Research', 'Image', 'data', 'is', 'scarce', 'in', 'most', 'cases', 'So', 'we', 'created', 'a', 'database', 'of', 'numerous', 'mug', 'shots', 'and', 'possible', 'variations', 'that', 'can', 'occur', 'Researchers', 'also', 'seek', 'to', 'develop', 'algorithms', 'within', 'the', 'next', 'five', 'years', 'to', 'help', 'identify', 'special', 'traits', 'of', 'dementia', 'patients', 'and', 'project', 'the', 'current', 'appearance', 'of', 'long', 'lost', 'children', 'through', 'use', 'of', 'genetic', 'information'], ['국내', '정보통', '신', '기술', 'ICT', '기업', '의', '연구개발', '비', '가', '40조원', '을', '돌파', '한', '것', '으로', '나타나다', '과학기술', '정보통신부', '장관', '최', '기', '영', '이하', '과', '기', '정통부', '늘다', '최근', '조사', '되다', '2018년', 'ICT', 'R', 'D', '통계', '를', '통해', '우리나라', 'ICT', '기업', '의', '2018년', '연구개발', '비', '가', '전', '년', '보다', '11', '9', '증가', '한', '40조', '2202억원', '으로', '집계', '돼다', '처음', '으로', '40조원', '을', '돌파', '하다', '밝히다', '전체', '산업', '에서', '차지', '하다', '비중', '도', '58', '4', '를', '기록', '하다', '등', 'ICT', '가다', '우리나라', 'R', 'D', '를', '주도하다', '있다', '것', '으로', '나타나다', 'ICT', '연구개발', '인력', '도', '16만', '9281', '명', '으로', '전', '년', '대비', '7', '증가', '하다', '최근', '5년', '간', '연', '평균', '증가', '율', '2013', '2018년', '3', '5', '보다', '크게', '늘어나다', '것', '으로', '조사', '돼다', '기', '업유', '형', '별로', '는', '벤처기업', '의', '연', '구', '활동', '이', '활발하다', '벤처기업', '들', '의', '연구개발', '비다', '전', '년', '대비', '19', '7', '증가', '한', '3', '3조원', '으로', '대', '중소기업', '에', '비다', '크다', '것', '으로', '나타나다', '전', '년', '대비', '증가', '율', '순서', '는', '벤처기업', '19', '7', '중견', '기업', '14', '5', '대기업', '11', '4', '중소기업', '5', '0', '순이', '다', '업종', '별로', '는', '반도체', '스마트폰', '등', '이', '포함', '되다', '정보통', '신', '방송', '기', '기업', '이', '연구개발', '비', '의', '92', '6', '연구개발', '인력', '의', '73', '8', '로', '크다', '비중', '을', '차지', '하다', 'ICT', '연구개발', '인력', '중', '소프트웨어', '및', '디지털콘텐츠', '개발', '제', '작업', '23', '1', '비중', '의', '꾸준하다', '증가', '추세', '를', '확인', '하다', '수', '있다', '과', '기', '정통부', '오상진', '정보통', '신', '산업', '정책', '관', '은', '5', 'G', 'ㆍ', '인공', '지능', 'AI', '등', 'ICT', 'DNA', 'Data', 'ㆍ', 'Network', 'ㆍ', 'AI', '핵심', '기술', '이', '고도화', '되다', '새롭다', '시장', '을', '선점', '하다', '위해', 'ICT', '기업', '들', '의', '연구개발', '활동', '이', '활발해지다', '있다', '것', '으로', '분석', '돼다', '며', '이번', '통계', '결과', '를', '참고', '하다', 'ICT', 'R', 'D', '정책', '을', '수립', '하다', '한편', '국내', '기업', '의', 'R', 'D', '투자', '촉진', '및', '경쟁력', '강화', '를', '위해', '지속', '적', '으로', '노력', '하다', '나가다', '고', '밝히다'], ['얼마', '전', '개봉', '한', '영화', '나이트', '크다', '롤러', '감독', '대다', '길', '로이', '를', '알다', '직장', '이', '없다', '루이스', '블룸', '제이크', '질렌할', '은', '야간', '운전', '을', '하다', '우연히', '생생하다', '교통', '사고', '현장', '의', '모습', '을', '카메라', '에', '담다', '방송국', '에', '팔', '아', '넘기다', '프리랜서', '카메라맨', '일명', '나이트', '크다', '롤러', 'night', 'crawler', '를', '보다', '되다', '직감', '적', '으로', '돈', '이', '되다', '것', '을', '파악', '한', '루이스', '는', '곧바로', '캠코더', '와', '경찰', '무전기', '를', '구입', '하고', '경찰', '의', '무전', '을', '외우다', '등', '노하우', '를', '익히다', '가다', '그', '후', '경찰', '무전', '을', '엿', '들', '어', '경찰', '보다', '빨리', '사건', '사고', '현장', '을', '찾아가다', '생생하다', '살인', '현장', '을', '촬영', '하고', '급하다', '현장', '을', '떠나다', '범인', '까지', '목격', '하다', '수확', '을', '거두다', '주파수', '를', '엿들으', '면', '돈', '이', '보이다', '13년', '전', '제', '가', '지역', '근무', '를', '하다', '때', '의', '일', '이다', '사', '회부', '경찰', '출입', '기자', '인', '저', '역시', '교통사고', '현장', '을', '빨리', '가다', '촬영', '을', '하다', '하다', '중요하다', '시절', '이다', '조금', '만', '늦다', '가면', '이미', '경찰', '이', '오다', '교통', '방해', '가', '안되다', '현장', '을', '다', '정리', '하다', '때문', '에', '찍', '을', '만', '한', '게', '없다', '경우', '가', '많다', '그렇게', '다른', '방송사', '들', '은', '다', '찍다', '방송', '을', '내다', '저만', '촬영', '을', '못', '하다', '곤란하다', '되다', '이렇다', '상황', '을', '언론', '계', '에서는', '물', '먹다', '고', '표현', '하다', '그렇다', '일', '을', '몇번', '겪다', '중', '우연히', '저', '는', '사설', '견인', '차량', '들', '이', '경찰', '보다', '빨리', '교통사고', '현장', '에', '오다', '사실', '을', '알다', '견인', '차량', '들', '이', '어떻다', '경우', '에는', '3', '4', '대가', '하다', '번', '에', '오다', '사고', '난', '차량', '을', '먼저', '견인', '하다', '가다', '경쟁', '하다', '경찰', '들', '이', '교통사고', '상황', '을', '자다', '알다', '않다', '어떻다', '사고', '소식', '을', '빨리', '듣다', '오다', '궁금하다', '그렇다', '차', '에', '견인', '차량', '안', '에', '있다', '무전기', '를', '보고', '기사', '들', '이', '경찰', '무전', '을', '듣다', '있다', '사실', '을', '알', '게', '돼다', '그', '당시', '다른', '방송사', '들', '이', '경찰', '무전', '을', '듣다', '출동', '하다', '견인', '차량', '관계자', '에게', '정보', '를', '얻다', '신속하다', '교통사고', '현장', '에', '오다', '촬영', '을', '한다는', '사실', '도', '알', '게', '돼다', '하지만', '허가', '받다', '않다', '주파수', '를', '엿듣는', '행위', '즉', '허가', '받다', '않다', '무선', '국', '을', '사용', '하다', '행위', '는', '3년', '이하', '징역', '이나', '3000만원', '이하', '벌금', '을', '물어', '야', '하다', '만큼', '매우', '무겁다', '죄', '이다', '인천공항', '근처', '덤프', '트럭', '기사', '들', '의', '불법', '무전기', '는', '왜', '문제', '인가', '취재', '진', '이', '인천공항', '바로', '옆', '에', '있다', '하다', '공', '사', '현장', '을', '가보다', '덤프', '트럭', '수십', '대가', '흙', '먼지', '를', '날리다', '부지런하다', '흙', '을', '퍼', '나르다', '있다', '이', '들', '은', '각자', '차량', '을', '이동', '시키다', '일', '을', '하다', '보다', '수시로', '연락', '을', '주다', '받다', '위해', '차량', '용', '무전기', '를', '사용', '하다', '무전기', '를', '사용', '하다', '것', '은', '불법', '이', '아니다', '다만', '기존', '산업', '용', '으로', '할당', '받다', '주파수', '에', '사용자', '가', '몰리다', '교신', '이', '자주', '끊기다', '등', '통화', '가', '어려워지다', '주파수', '대역', '을', '불법', '변경', '한', '무전기', '를', '구입', '하다', '사용', '하고', '있다', '주파수', '대역', '을', '찾다', '이', '들', '이', '통화', '하다', '내용', '을', '들다', '보다', '업무', '적', '인', '이야기', '외', '에도', '과', '적', '단속', '차량', '이', '어디', '에', '있다', '서로', '알다', '있다', '차량', '에', '과', '적', '을', '하다', '조심하다', '눈치', '가', '역', '력', '하다', '문제', '는', '이렇게', '지정', '되다', '주파수', '가', '아니다', '다른', '대역', '의', '주파수', '를', '사용', '하다', '경우', '안전', '에', '심각하다', '위험', '이', '오다', '수도', '있다', '겁니다', '불법', '으로', '주파수', '대역', '을', '바꾸다', '무전기', '로', '무전', '을', '하다', '있다', '공', '사', '현장', '은', '바로', '인천공항', '과', '맞닿다', '있다', '곳', '이다', '공항', '에서는', '항공기', '조종사', '와', '관제', '센터', '그리고', '지상', '에서', '비행기', '의', '이착륙', '을', '돕다', '지상', '직', '직원', '들', '이', '쉬다', '새', '없이', '무전기', '로', '통화', '를', '하다', '있다', '그런데', '만약', '이', '주파수대', '를', '덤프', '트럭', '기사', '들', '이', '사용', '한', '다', '면', '시간', '을', '다투다', '이착륙', '과', '관련', '한', '업무', '협조', '통화', '에', '지장', '을', '받다', '자칫', '대형', '사고', '로', '이어지다', '수', '있다', '게', '서울', '전파', '관리소', '공무원', '의', '설명', '이다', '그렇다', '일이', '일어나지', '는', '말다', '관제', '센터', '와', '조종사', '가', '착륙', '과정', '에서', '교신', '을', '하다', '이', '게', '방해', '를', '받다', '큰일', '이', '겠다', '서', '울', '전파', '관리소', '를', '취재', '하다', '가보다', '이', '곳', '에서는', '24시간', '이렇다', '불법', '주파수', '사용', '실태', '를', '감시', '하고', '있다', '누가', '허가', '받다', '않다', '주파수', '대역', '을', '침범', '하다', '사용', '하고', '있다', '실시간', '으로', '적발', '하다', '겁니다', '모든', '주파수', '대역', '의', '통화', '내', '역', '과', '목소리', '를', '들다', '수', '있다', '신기하다', '하다', '재미있다', '실제', '로', '이', '덤프', '트럭', '기사', '들', '은', '지정', '되다', '산업', '통', '신용', '주파수', '가', '아니다', '공공', '업무', '용', '지하철', '관리', '업무', '171', '대역', '을', '사용', '하다', '현재', '시험', '운행', '중', '인', '인천', '도시철도', '2', '호선', '차량', '운행', '시스템', '에', '장애', '를', '주다', '기관사', '들', '끼리', '무선', '교신', '을', '하다', '자꾸', '교신', '이', '안되다', '현상', '이', '발생', '하다', '서', '울', '전파', '관리소', '에', '원인', '을', '의뢰', '하다', '보다', '트럭', '기사', '들', '이', '불법', '으로', '이', '주파수', '대역', '을', '사용', '하고', '있다', '겁니다', '당시', '엔', '시운전', '이어서', '그나마', '다행', '이다', '만약', '실제', '운행', '중', '이다', '기관사', '들', '사이', '의', '교신', '을', '방해', '하다', '전동차', '를', '세우다', '되다', '상황', '도', '발생', '하다', '수', '있다', '그렇다', '경우', '승객', '들', '의', '피해', '로', '이어지다', '그', '파급', '효과', '는', '매우', '크다', '수', '밖에', '없다', '서', '울', '전파', '관리소', '가', '지난해', '관할', '수도권', '에서', '불법', '전파', '설비', '등', '을', '단속', '한', '결과', '허가', '없이', '무전기', '등', '을', '개설', '한', '불법', '무선', '국', '은', '114', '건', '승인', '받다', '않다', '주파수', '를', '사용', '한', '불법', '주파수', '는', '26', '건', '에', '달', '한', '것', '으로', '나타나다', '지난', '2013년', '과', '비교', '하다', '불법', '무선', '국', '은', '117', '건', '에서', '다소', '줄다', '불법', '주파수', '는', '전', '년', '16', '건', '보다', '62', '나', '크게', '늘어나다', '것', '이다', '사용자', '대부분', '은', '건설', '현장', '에서', '일', '하다', '덤프', '트럭', '운전기사', '인', '것', '으로', '조사', '돼다', '사기', '도박', '토익시험', '부정행위', '등', '범죄', '수단', '으로', '악용', '되다', '수도', '이', '같다', '불법', '주파수', '대역', '사용', '은', '다른', '통신', '에', '혼선', '을', '주다', '것', '은', '물론', '사', '기', '도박', '이나', '시험', '장', '부정행위', '등', '여러', '범죄', '수단', '으로', '악용', '되어다', '사회', '문제', '가', '되다', '경우', '가', '많다', '사기', '도박', '은', '귀', '에', '식별', '하다', '어렵다', '이어폰', '을', '끼', '고', '조작', '되다', '카드', '패', '카드', '패', '뒷', '면', '에', '형광', '색칠', '을', '하다', '특정', '카메라', '로', '읽다', '있다', '방법', '를', '밖', '에서', '읽다', '이야기', '해주다', '경우', '들이다', '토익', '시험', '의', '경우', '에도', '외부', '에서', '이어폰', '으로', '답', '을', '알다', '등', '불법', '주파수', '를', '사용', '하다', '경우', '가', '많다', '종종', '적발', '되다', '하다', '또', '개인', '사생활', '침해', '의', '문제', '가', '대두', '되다', '수', '있다', '어디', '든', '가깝다', '곳', '에', '있다', '특정', '주파수', '를', '이용', '하다', '도청', '이나', '감청', '도', '가능하다', '때문', '이', '죠', '또', '텔레비전', '수', '신', '장애', '와', '더불다', '전자기기', '오', '작', '동의', '문제', '가', '생기다', '있다', '등', '많다', '부작용', '을', '야기', '시키다', '수', '있다', '주파수', '보이지', '않다', '중요하다', '통신', '수단', '이다', '그렇다', '함부로', '특정', '주파수', '를', '침범', '하', '거나', '불법', '무전기', '를', '사용', '하다', '안되다', '교신', '방해', '불법', '무전', '기승', '지하철', '사고', '위험']]\n",
            "[['<start>', 'Missing', 'People', 'Measure'], ['<start>', '국내', 'ICT', '기업', '연구개발', '비', '40조원', '돌파'], ['<start>', '주파수', '훔치다', '쓰다', '엉뚱하다', '대형', '사고', '나다']]\n",
            "[['Missing', 'People', 'Measure', '<end>'], ['국내', 'ICT', '기업', '연구개발', '비', '40조원', '돌파', '<end>'], ['주파수', '훔치다', '쓰다', '엉뚱하다', '대형', '사고', '나다', '<end>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3lvBkT8svyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "7aef0a30-325c-4962-b8cf-55634e080b99"
      },
      "source": [
        "tokenizer_en = Tokenizer()\n",
        "tokenizer_en.fit_on_texts(encoder_input)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(encoder_input)\n",
        "\n",
        "tokenizer_de = Tokenizer()\n",
        "tokenizer_de.fit_on_texts(decoder_input)\n",
        "tokenizer_de.fit_on_texts(decoder_output)\n",
        "decoder_input = tokenizer_de.texts_to_sequences(decoder_input)\n",
        "decoder_output = tokenizer_de.texts_to_sequences(decoder_output)\n",
        "\n",
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[43952, 2563, 5652, 30352, 16047, 4179, 34120, 18406, 39760, 34121, 4606, 74194, 19750, 1273, 434, 16350, 564, 22864, 7725, 36640, 26341, 11348, 7485, 74195, 1273, 434, 7141, 4396, 18004, 2139, 27570, 1273, 28845, 1196, 30353, 434, 32072, 5914, 10641, 5652, 49574, 34122, 3507, 434, 30354, 1196, 26342, 3618, 19751, 5073, 19239, 2187, 18799, 43953, 564, 27571, 12702, 74196, 32073, 10131, 760, 23613, 16047, 981, 18406, 14123, 5058, 22864, 24441, 7055, 74197, 1273, 11691, 19240, 8106, 3647, 74198, 3507, 7485, 43952, 74199, 7949, 7485, 20804, 30355, 2139, 11691, 20275, 1273, 43954, 22864, 7725, 74200, 22102, 24442, 434, 18407, 564, 434, 22864, 58014, 13026, 434, 27572, 4396, 16638, 14529, 434, 7569, 17278, 19751, 5073, 34123, 23614, 24443, 9981, 58015, 30354, 12461, 21423, 1196, 30353, 434, 22864, 1273, 434, 11568, 16930, 34124, 1196, 49575, 17647, 981, 17648, 5726, 5073, 49576, 20276, 434, 13737, 2139, 16351, 5914, 10641, 5652, 8338, 368, 3155, 49577, 3905, 39761, 3618, 18800, 19239, 564, 5073, 14971, 7686, 7974, 3475, 434, 5073, 981, 19752, 564, 74201, 981, 434, 13737, 857, 23615, 28846, 3647, 49578, 981, 25367, 7687, 4180, 11349, 3619, 6253, 6275, 7915, 3618, 3155, 368, 22864, 13737, 3688, 3629, 49579, 11348, 4606, 36641, 11692, 20277, 3619, 49580, 564, 10740, 23616, 981, 8788, 857, 5726, 15529, 17279, 10850, 36642, 22864, 4606, 368, 58016, 32074, 564, 12335, 10741, 1381, 8946, 16639, 17649, 6908, 228, 3905, 434, 5073, 981, 15530, 3629, 1831, 3618, 7055, 5704, 434, 12703, 2497, 434, 74202, 17280, 19753, 434, 23617, 7055, 18801, 36643, 434, 21424, 981, 8789, 39762, 10362, 564, 12335, 8999, 16931, 3688, 3629, 27573, 7915, 474, 981, 59, 298, 43955, 7916, 9476, 43956, 26343, 26344, 2534, 5672, 2187, 9812, 13738, 2826, 10362, 4949, 2139, 58017, 1273, 11691, 19240, 7569, 7758, 21425, 368, 25368, 564, 36641, 74203, 58018, 981, 12462, 39763, 3586, 3688, 28847, 10641, 6297, 36644, 1196, 24444, 74204, 20278, 434, 8890, 14972, 8946, 1196, 12063, 36645, 16640, 28846, 564, 18406, 14123, 981, 6958, 434, 8999, 39764, 564, 8615, 30352, 16047, 7687, 9477, 564, 10206, 7686], [136, 1764, 249, 31, 1063, 188, 4, 1130, 259, 9, 32075, 2, 4616, 18, 13, 10, 90, 271, 1218, 855, 868, 117, 913, 769, 20, 117, 941, 68, 104, 238, 11, 1728, 1063, 1077, 298, 2033, 6, 45, 261, 1063, 188, 4, 1728, 1130, 259, 9, 47, 444, 34, 1142, 451, 231, 18, 23618, 58019, 10, 2505, 30, 269, 10, 32075, 2, 4616, 1, 56, 392, 179, 15, 838, 1, 2020, 25, 5337, 128, 6, 468, 1, 23, 1063, 70, 261, 1077, 298, 6, 1586, 7, 13, 10, 90, 1063, 1130, 1133, 25, 9292, 58020, 152, 10, 47, 444, 672, 349, 231, 1, 104, 1197, 182, 27, 629, 231, 804, 8498, 1728, 59, 93, 34, 415, 577, 13, 10, 238, 30, 117, 49581, 167, 1180, 12, 2880, 4, 27, 36, 289, 3, 1310, 2880, 16, 4, 1130, 352, 47, 444, 672, 348, 349, 231, 18, 59, 19754, 10, 168, 2129, 5, 352, 74, 13, 10, 90, 47, 444, 672, 231, 804, 4902, 12, 2880, 348, 349, 4148, 188, 1429, 93, 3203, 1142, 128, 2129, 93, 522, 13739, 38, 5632, 1180, 12, 578, 296, 23, 3, 315, 11, 1764, 249, 731, 117, 188, 3, 1130, 259, 4, 6462, 228, 1130, 1133, 4, 5915, 387, 19, 74, 2020, 2, 838, 1, 1063, 1130, 1133, 72, 1097, 83, 11449, 33, 113, 523, 2143, 50, 2020, 4, 2087, 231, 1725, 6, 143, 1, 17, 7, 20, 117, 941, 27574, 1764, 249, 179, 452, 541, 8, 93, 342, 2363, 181, 219, 474, 23, 1063, 413, 4949, 2363, 6059, 2363, 474, 445, 31, 3, 4054, 11, 87, 248, 2, 3310, 1, 67, 1063, 188, 16, 4, 1130, 289, 3, 5394, 7, 13, 10, 86, 30, 156, 51, 2033, 43, 6, 4441, 1, 1063, 1077, 298, 452, 2, 2023, 1, 579, 136, 188, 4, 1077, 298, 581, 1236, 83, 1314, 1121, 6, 67, 483, 21, 10, 655, 1, 508, 28, 56], [1747, 47, 5338, 18, 735, 8027, 74, 14973, 3440, 350, 1340, 10132, 6, 721, 4820, 3, 44, 6780, 20279, 16641, 74205, 8, 3867, 1539, 2, 1, 5370, 4067, 1570, 534, 670, 4, 465, 2, 758, 5, 1154, 14124, 5, 1592, 663, 3390, 19755, 49582, 3855, 8027, 74, 14973, 17650, 58021, 6, 34, 11, 13740, 21, 10, 1587, 3, 11, 13, 2, 589, 18, 6780, 12, 3730, 23619, 24, 3223, 13027, 6, 2997, 26, 3223, 4, 13741, 2, 13368, 23, 5475, 6, 4551, 70, 35, 189, 3223, 13741, 2, 15255, 16, 676, 3223, 34, 1417, 1281, 534, 670, 2, 3670, 4067, 6235, 670, 2, 749, 26, 5958, 670, 2, 2692, 5088, 46, 5876, 1, 4418, 2, 1723, 1584, 6, 74206, 364, 1587, 3, 134, 9000, 47, 113, 9, 120, 2819, 6, 1, 57, 4, 201, 14, 491, 39765, 3223, 5581, 330, 22, 223, 427, 4373, 670, 2, 1417, 70, 749, 2, 1, 1, 193, 2802, 14, 1234, 99, 2559, 5163, 422, 3223, 3, 62, 1570, 2041, 9, 3050, 670, 2, 38, 2074, 1, 37, 5, 7440, 2, 99, 18, 247, 44, 60, 9, 61, 1992, 80, 4486, 16, 8, 38, 2078, 731, 2, 290, 34125, 749, 2, 147, 1, 8107, 11, 103, 199, 2, 1693, 360, 89, 211, 386, 28, 1372, 1, 209, 201, 2, 39766, 1000, 72, 5370, 223, 12, 16642, 7021, 816, 16, 3, 3223, 34, 1417, 4373, 670, 5, 62, 123, 2, 721, 7021, 816, 16, 3, 106, 60, 42, 59, 128, 1786, 1, 400, 5, 62, 534, 1702, 816, 2, 794, 7021, 1, 70, 768, 1, 3223, 16, 3, 4373, 199, 2, 251, 721, 32, 106, 534, 1965, 2, 1417, 2144, 62, 3173, 209, 221, 5, 7021, 816, 169, 5, 7, 13027, 6, 305, 1379, 16, 3, 3223, 13741, 2, 2144, 7, 123, 2, 297, 247, 30, 35, 605, 80, 4486, 16, 3, 3223, 13741, 2, 2144, 7260, 1, 7021, 816, 584, 137, 121, 6, 357, 1720, 4373, 670, 5, 62, 749, 2, 240, 123, 25, 297, 247, 30, 157, 1751, 66, 32, 1584, 6, 58022, 1931, 556, 1751, 66, 32, 1308, 667, 2, 55, 1, 1931, 12, 1328, 769, 12064, 85, 23620, 769, 10940, 2, 9537, 1694, 1, 366, 175, 2369, 13539, 14, 12189, 2764, 36646, 3833, 1379, 16, 4, 2006, 13027, 12, 1401, 119, 1916, 1645, 1262, 3, 12189, 291, 2981, 5, 7, 1, 300, 491, 670, 2, 7290, 36646, 3833, 1688, 1786, 3826, 1279, 6, 5789, 18408, 3826, 2, 3996, 3851, 7, 3, 16, 8, 4552, 816, 2, 548, 73, 201, 2, 1, 34, 4419, 5633, 2, 285, 66, 67, 816, 294, 13027, 6, 55, 1, 13027, 6, 55, 1, 13, 8, 2006, 3, 76, 1238, 174, 179, 294, 10, 5540, 66, 1584, 5, 830, 9, 3834, 3125, 3, 1296, 4767, 23, 3003, 9, 5213, 1584, 3385, 2, 2006, 2211, 18, 13027, 6, 2997, 1, 55, 26, 7, 1584, 3385, 2, 375, 3, 16, 3, 3003, 1, 426, 2, 149, 34, 1187, 21, 22, 905, 757, 124, 20, 21, 5959, 816, 3, 1423, 5, 7, 640, 721, 7, 816, 5, 20, 21, 2, 1, 3963, 10286, 9, 1672, 336, 1, 119, 12, 634, 1948, 11, 1584, 9, 76, 80, 3385, 4, 1584, 6, 55, 1, 60, 554, 5, 1010, 313, 3, 62, 458, 7, 1008, 2006, 10, 1584, 3385, 2, 626, 13027, 19, 13741, 2, 1, 7, 300, 491, 670, 8, 291, 12189, 20, 11808, 7, 206, 14, 3272, 89, 1166, 3954, 24, 3508, 225, 227, 1192, 15, 1421, 4, 7917, 2, 1733, 1192, 4856, 2221, 16, 3, 293, 689, 528, 13027, 19, 3003, 6, 1, 7, 583, 1317, 3, 22103, 6, 36646, 3833, 1379, 16, 3, 55, 18, 38, 364, 142, 2, 5452, 7917, 20, 100, 18, 1187, 5229, 3003, 5, 5352, 2, 66, 5297, 1056, 534, 19, 533, 17, 7, 247, 381, 901, 15531, 6213, 4, 116, 14, 209, 692, 4779, 12, 1338, 3508, 225, 24, 3954, 9, 1140, 130, 15, 3125, 2, 1, 3, 247, 2041, 6, 66, 16643, 3, 7291, 252, 2900, 901, 15531, 6, 1645, 1, 7290, 3, 206, 89, 2526, 103, 2006, 1584, 55, 3792, 6, 1318, 26, 7, 4255, 1751, 66, 32, 1584, 3385, 2, 8438, 1, 55, 26, 7, 943, 10, 6254, 1, 1008, 277, 1584, 3385, 4, 3003, 164, 1672, 20, 1873, 6, 149, 17, 7, 4428, 1, 3008, 212, 19, 3, 36646, 3833, 1379, 16, 8, 1948, 11, 179, 1536, 6959, 1584, 9, 76, 1345, 1187, 294, 4687, 283, 1187, 19241, 3385, 2, 55, 1, 125, 486, 2156, 72, 22, 2985, 23621, 53, 13540, 816, 2156, 145, 5, 874, 6, 285, 26345, 16, 3944, 1308, 3125, 2, 1, 9346, 3125, 3, 3050, 229, 3, 84, 1, 252, 2900, 901, 15531, 5, 288, 2, 5029, 1, 34, 3833, 1379, 16, 3, 2006, 10, 3, 1584, 3385, 2, 55, 26, 7, 1008, 605, 693, 12463, 1667, 7056, 7950, 14, 1317, 212, 2156, 72, 14, 26345, 16, 282, 4, 3125, 2, 2041, 1, 26346, 6, 1646, 11, 199, 25, 84, 1, 17, 7, 209, 60, 3715, 16, 4, 484, 19, 533, 35, 3821, 160, 12, 175, 74, 17, 739, 44, 252, 2900, 901, 15531, 9, 328, 6822, 2216, 15, 2006, 901, 1707, 23, 2, 5959, 18, 43, 1751, 528, 13027, 23, 2, 5339, 18, 2006, 1308, 667, 8, 12704, 443, 1673, 66, 32, 1584, 6, 55, 18, 2006, 1584, 12, 2520, 443, 5, 114, 18, 13, 10, 90, 109, 1522, 20, 409, 1, 2006, 1308, 667, 8, 10742, 443, 15, 2173, 2522, 2006, 1584, 12, 47, 444, 1336, 443, 34, 5476, 79, 415, 577, 13, 14, 830, 337, 8, 880, 670, 15, 201, 1, 36646, 3833, 18802, 22, 13, 10, 238, 30, 6298, 6276, 74207, 10556, 23, 2262, 2042, 10, 6214, 11, 458, 3, 48, 2006, 1584, 3385, 55, 8, 80, 418, 5, 16352, 2, 285, 13, 8, 398, 491, 117, 6276, 85, 486, 236, 10556, 23, 273, 2262, 2042, 10, 6214, 132, 314, 119, 9, 11, 60, 9, 61, 6298, 6276, 8, 2419, 5, 1988, 1, 322, 5453, 2, 5353, 28, 1352, 11, 2916, 4313, 2916, 4313, 3556, 364, 5, 2370, 22104, 2, 1, 602, 758, 19, 1998, 7, 165, 6, 1378, 15, 1998, 905, 490, 60, 964, 36647, 486, 4, 60, 124, 771, 15, 5453, 10, 1932, 2, 721, 23, 2006, 1584, 6, 55, 1, 60, 9, 61, 2631, 6254, 11, 1, 133, 600, 5477, 3648, 4, 119, 9, 4397, 11, 17, 7, 1423, 3105, 840, 206, 5, 7, 602, 1584, 6, 77, 1, 10363, 85, 10743, 25, 122, 37, 3, 1052, 133, 9732, 17, 249, 874, 24, 1550, 3861, 862, 1456, 2978, 119, 9, 359, 7, 23, 61, 1098, 2, 3424, 73, 17, 7, 1584, 2159, 32, 193, 418, 2042, 14, 209, 11934, 602, 1584, 6, 8438, 241, 623, 2006, 13027, 6, 55, 1, 3050, 3125, 2041, 2006, 13741, 6489, 4687, 534, 313]]\n",
            "[[1, 10102, 10103, 10104], [1, 31, 163, 165, 806, 49, 10105, 935], [1, 770, 4303, 516, 6273, 1080, 395, 1135]]\n",
            "[[10102, 10103, 10104, 2], [31, 163, 165, 806, 49, 10105, 935, 2], [770, 4303, 516, 6273, 1080, 395, 1135, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r17ip8Ohrem7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c08c69bc-a576-48de-cd94-458608614c93"
      },
      "source": [
        "print(f\"인코더 데이터 단어 개수 : {len(tokenizer_en.word_index)}\")\n",
        "print(f\"디코더 데이터 단어 개수 : {len(tokenizer_de.word_index)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코더 데이터 단어 개수 : 120945\n",
            "디코더 데이터 단어 개수 : 16977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ekE0KGs4b-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b96fadbc-cca4-4edd-e357-c2e59b8bd137"
      },
      "source": [
        "len_en = list(map(len, encoder_input))\n",
        "len_de = list(map(len, decoder_input))\n",
        "\n",
        "plt.hist(len_en, label='en', alpha=0.7)\n",
        "plt.hist(len_de, label='de', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLXs-ZHDs8vB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "919f1c16-dc7a-48cf-f017-1550343f8275"
      },
      "source": [
        "print(f\"인코더 데이터 길이 평균 : {np.mean(len_en)}\")\n",
        "print(f\"디코더 데이터 길이 평균 : {np.mean(len_de)}\")\n",
        "print(f\"인코더 데이터 길이 중간값 : {np.median(len_en)}\")\n",
        "print(f\"디코더 데이터 길이 중간값 : {np.median(len_de)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코더 데이터 길이 평균 : 508.78053511950515\n",
            "디코더 데이터 길이 평균 : 9.077998609128509\n",
            "인코더 데이터 길이 중간값 : 353.0\n",
            "디코더 데이터 길이 중간값 : 9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B86ZHi9s9mg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "d1f7be26-81b4-4fd5-9600-b6d719eeccaa"
      },
      "source": [
        "# padding=\"post\" : 앞부터 문장, 뒤에 0값을 채우기 위해\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "decoder_output = pad_sequences(decoder_output, padding=\"post\")\n",
        "\n",
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])\n",
        "print(encoder_input.shape)\n",
        "print(decoder_input.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[43952  2563  5652 ...     0     0     0]\n",
            " [  136  1764   249 ...     0     0     0]\n",
            " [ 1747    47  5338 ...     0     0     0]]\n",
            "[[    1 10102 10103 10104     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0]\n",
            " [    1    31   163   165   806    49 10105   935     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0]\n",
            " [    1   770  4303   516  6273  1080   395  1135     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0]]\n",
            "[[10102 10103 10104     2     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0]\n",
            " [   31   163   165   806    49 10105   935     2     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0]\n",
            " [  770  4303   516  6273  1080   395  1135     2     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0]]\n",
            "(27321, 8022)\n",
            "(27321, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPV_QUuctBrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 나중에 prediction 할 때 사용하기 위함(인덱스로 단어 찾기)\n",
        "de_to_index = tokenizer_de.word_index\n",
        "index_to_de = tokenizer_de.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs_OOfmXtPDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_size = 5000\n",
        "encoder_input_train = encoder_input[:-test_size]\n",
        "decoder_input_train = decoder_input[:-test_size]\n",
        "decoder_output_train = decoder_output[:-test_size]\n",
        "\n",
        "encoder_input_test = encoder_input[-test_size:]\n",
        "decoder_input_test = decoder_input[-test_size:]\n",
        "decoder_output_test = decoder_output[-test_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuyAygO8unKh",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH4vNR96v7zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyperparameter\n",
        "word_embedding = 100\n",
        "LSTM_unit = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RbAniExul4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = Input(shape=(encoder_input.shape[1],))\n",
        "encoder_embed = Embedding(len(tokenizer_en.word_index)+1, word_embedding)(encoder_inputs)\n",
        "encoder_mask = Masking(mask_value=0)(encoder_embed)\n",
        "encoder_outputs, forward_h_state, forward_c_state, backward_h_state, backward_c_state = Bidirectional(LSTM(LSTM_unit, return_state=True, return_sequences=True))(encoder_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1yWuKcSvJTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(decoder_input.shape[1],))\n",
        "decoder_embed = Embedding(len(tokenizer_de.word_index)+1, word_embedding)(decoder_inputs)\n",
        "decoder_mask = Masking(mask_value=0)(decoder_embed)\n",
        "decoder_lstm = Bidirectional(LSTM(LSTM_unit, return_sequences=True, return_state=True))\n",
        "decoder_outputs, _, _, _, _ = decoder_lstm(decoder_mask, initial_state=[forward_h_state, forward_c_state, backward_h_state, backward_c_state])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-GNBwxmvK6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from attention import AttentionLayer\n",
        "\n",
        "attn_layer = AttentionLayer()\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "decoder_concat_input = Concatenate()([decoder_outputs, attn_out])\n",
        "\n",
        "decoder_dense = Dense(len(tokenizer_en.word_index)+1, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_dense(decoder_concat_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQUxOwowtwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "bf687943-5e6e-4ca4-d59a-586a6aa539e4"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 8022)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 21)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 8022, 100)    12094600    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 21, 100)      1697800     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking (Masking)               (None, 8022, 100)    0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "masking_1 (Masking)             (None, 21, 100)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 8022, 128),  84480       masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) [(None, 21, 128), (N 84480       masking_1[0][0]                  \n",
            "                                                                 bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, 21, 128), (N 32896       bidirectional[0][0]              \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 21, 256)      0           bidirectional_1[0][0]            \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 21, 120946)   31083122    concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 45,077,378\n",
            "Trainable params: 45,077,378\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6nfSze1x7Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "model_check = ModelCheckpoint('./seq2seq_news_title.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFeVS_36yCVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c61f887-ce8d-41eb-a907-ed555e9d68e2"
      },
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_output_train,\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_output_test),\n",
        "          batch_size=32, epochs=100,\n",
        "          callbacks=[early_stop, model_check])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 3.2549 - acc: 0.6183\n",
            "Epoch 00001: val_acc improved from -inf to 0.63664, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 851s 1s/step - loss: 3.2549 - acc: 0.6183 - val_loss: 2.7718 - val_acc: 0.6366\n",
            "Epoch 2/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 2.5260 - acc: 0.6560\n",
            "Epoch 00002: val_acc improved from 0.63664 to 0.67435, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 839s 1s/step - loss: 2.5260 - acc: 0.6560 - val_loss: 2.3958 - val_acc: 0.6744\n",
            "Epoch 3/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 2.2555 - acc: 0.6901\n",
            "Epoch 00003: val_acc improved from 0.67435 to 0.70129, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 837s 1s/step - loss: 2.2555 - acc: 0.6901 - val_loss: 2.1970 - val_acc: 0.7013\n",
            "Epoch 4/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 2.0422 - acc: 0.7208\n",
            "Epoch 00004: val_acc improved from 0.70129 to 0.72866, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 833s 1s/step - loss: 2.0422 - acc: 0.7208 - val_loss: 2.0210 - val_acc: 0.7287\n",
            "Epoch 5/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 1.8655 - acc: 0.7488\n",
            "Epoch 00005: val_acc improved from 0.72866 to 0.75386, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 836s 1s/step - loss: 1.8655 - acc: 0.7488 - val_loss: 1.8760 - val_acc: 0.7539\n",
            "Epoch 6/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 1.7154 - acc: 0.7742\n",
            "Epoch 00006: val_acc improved from 0.75386 to 0.77626, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 836s 1s/step - loss: 1.7154 - acc: 0.7742 - val_loss: 1.7594 - val_acc: 0.7763\n",
            "Epoch 7/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 1.5866 - acc: 0.7972\n",
            "Epoch 00007: val_acc improved from 0.77626 to 0.79878, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 836s 1s/step - loss: 1.5866 - acc: 0.7972 - val_loss: 1.6281 - val_acc: 0.7988\n",
            "Epoch 8/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 1.5057 - acc: 0.8128\n",
            "Epoch 00008: val_acc improved from 0.79878 to 0.81475, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 837s 1s/step - loss: 1.5057 - acc: 0.8128 - val_loss: 1.5178 - val_acc: 0.8148\n",
            "Epoch 9/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 1.3672 - acc: 0.8347\n",
            "Epoch 00009: val_acc improved from 0.81475 to 0.83355, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 837s 1s/step - loss: 1.3672 - acc: 0.8347 - val_loss: 1.4317 - val_acc: 0.8336\n",
            "Epoch 10/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 1.2708 - acc: 0.8517\n",
            "Epoch 00010: val_acc improved from 0.83355 to 0.84485, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 836s 1s/step - loss: 1.2708 - acc: 0.8517 - val_loss: 1.3482 - val_acc: 0.8448\n",
            "Epoch 11/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 1.1854 - acc: 0.8661\n",
            "Epoch 00011: val_acc improved from 0.84485 to 0.86263, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 831s 1s/step - loss: 1.1854 - acc: 0.8661 - val_loss: 1.2605 - val_acc: 0.8626\n",
            "Epoch 12/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 1.1103 - acc: 0.8777\n",
            "Epoch 00012: val_acc improved from 0.86263 to 0.87084, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 830s 1s/step - loss: 1.1103 - acc: 0.8777 - val_loss: 1.2050 - val_acc: 0.8708\n",
            "Epoch 13/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 1.0402 - acc: 0.8880\n",
            "Epoch 00013: val_acc improved from 0.87084 to 0.88027, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 829s 1s/step - loss: 1.0402 - acc: 0.8880 - val_loss: 1.1314 - val_acc: 0.8803\n",
            "Epoch 14/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.9773 - acc: 0.8955\n",
            "Epoch 00014: val_acc improved from 0.88027 to 0.88882, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 830s 1s/step - loss: 0.9773 - acc: 0.8955 - val_loss: 1.0774 - val_acc: 0.8888\n",
            "Epoch 15/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.9231 - acc: 0.9030\n",
            "Epoch 00015: val_acc improved from 0.88882 to 0.89663, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 829s 1s/step - loss: 0.9231 - acc: 0.9030 - val_loss: 1.0269 - val_acc: 0.8966\n",
            "Epoch 16/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.8712 - acc: 0.9097\n",
            "Epoch 00016: val_acc improved from 0.89663 to 0.90162, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 828s 1s/step - loss: 0.8712 - acc: 0.9097 - val_loss: 0.9838 - val_acc: 0.9016\n",
            "Epoch 17/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.8244 - acc: 0.9148\n",
            "Epoch 00017: val_acc improved from 0.90162 to 0.90766, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 831s 1s/step - loss: 0.8244 - acc: 0.9148 - val_loss: 0.9310 - val_acc: 0.9077\n",
            "Epoch 18/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.7722 - acc: 0.9198\n",
            "Epoch 00018: val_acc improved from 0.90766 to 0.91073, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 832s 1s/step - loss: 0.7722 - acc: 0.9198 - val_loss: 0.8875 - val_acc: 0.9107\n",
            "Epoch 19/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.7332 - acc: 0.9232\n",
            "Epoch 00019: val_acc improved from 0.91073 to 0.91199, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 831s 1s/step - loss: 0.7332 - acc: 0.9232 - val_loss: 0.8724 - val_acc: 0.9120\n",
            "Epoch 20/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.7175 - acc: 0.9251\n",
            "Epoch 00020: val_acc improved from 0.91199 to 0.91617, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 831s 1s/step - loss: 0.7175 - acc: 0.9251 - val_loss: 0.8361 - val_acc: 0.9162\n",
            "Epoch 21/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.6897 - acc: 0.9281\n",
            "Epoch 00021: val_acc improved from 0.91617 to 0.91812, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 831s 1s/step - loss: 0.6897 - acc: 0.9281 - val_loss: 0.8297 - val_acc: 0.9181\n",
            "Epoch 22/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.6739 - acc: 0.9299\n",
            "Epoch 00022: val_acc improved from 0.91812 to 0.92154, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 832s 1s/step - loss: 0.6739 - acc: 0.9299 - val_loss: 0.7928 - val_acc: 0.9215\n",
            "Epoch 23/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.6432 - acc: 0.9329\n",
            "Epoch 00023: val_acc improved from 0.92154 to 0.92280, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 832s 1s/step - loss: 0.6432 - acc: 0.9329 - val_loss: 0.7737 - val_acc: 0.9228\n",
            "Epoch 24/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.6183 - acc: 0.9350\n",
            "Epoch 00024: val_acc improved from 0.92280 to 0.92507, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 829s 1s/step - loss: 0.6183 - acc: 0.9350 - val_loss: 0.7500 - val_acc: 0.9251\n",
            "Epoch 25/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.6099 - acc: 0.9358\n",
            "Epoch 00025: val_acc improved from 0.92507 to 0.92629, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 830s 1s/step - loss: 0.6099 - acc: 0.9358 - val_loss: 0.7486 - val_acc: 0.9263\n",
            "Epoch 26/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.6085 - acc: 0.9360\n",
            "Epoch 00026: val_acc improved from 0.92629 to 0.92650, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 830s 1s/step - loss: 0.6085 - acc: 0.9360 - val_loss: 0.7458 - val_acc: 0.9265\n",
            "Epoch 27/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5982 - acc: 0.9371\n",
            "Epoch 00027: val_acc improved from 0.92650 to 0.92807, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 828s 1s/step - loss: 0.5982 - acc: 0.9371 - val_loss: 0.7314 - val_acc: 0.9281\n",
            "Epoch 28/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5962 - acc: 0.9374\n",
            "Epoch 00028: val_acc did not improve from 0.92807\n",
            "698/698 [==============================] - 826s 1s/step - loss: 0.5962 - acc: 0.9374 - val_loss: 0.7351 - val_acc: 0.9280\n",
            "Epoch 29/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5862 - acc: 0.9388\n",
            "Epoch 00029: val_acc improved from 0.92807 to 0.92980, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 830s 1s/step - loss: 0.5862 - acc: 0.9388 - val_loss: 0.7218 - val_acc: 0.9298\n",
            "Epoch 30/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5600 - acc: 0.9410\n",
            "Epoch 00030: val_acc improved from 0.92980 to 0.93258, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 830s 1s/step - loss: 0.5600 - acc: 0.9410 - val_loss: 0.6907 - val_acc: 0.9326\n",
            "Epoch 31/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5461 - acc: 0.9424\n",
            "Epoch 00031: val_acc did not improve from 0.93258\n",
            "698/698 [==============================] - 827s 1s/step - loss: 0.5461 - acc: 0.9424 - val_loss: 0.7021 - val_acc: 0.9311\n",
            "Epoch 32/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5423 - acc: 0.9429\n",
            "Epoch 00032: val_acc improved from 0.93258 to 0.93404, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 831s 1s/step - loss: 0.5423 - acc: 0.9429 - val_loss: 0.6777 - val_acc: 0.9340\n",
            "Epoch 33/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5396 - acc: 0.9432\n",
            "Epoch 00033: val_acc did not improve from 0.93404\n",
            "698/698 [==============================] - 828s 1s/step - loss: 0.5396 - acc: 0.9432 - val_loss: 0.6872 - val_acc: 0.9339\n",
            "Epoch 34/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5282 - acc: 0.9445\n",
            "Epoch 00034: val_acc improved from 0.93404 to 0.93521, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 832s 1s/step - loss: 0.5282 - acc: 0.9445 - val_loss: 0.6712 - val_acc: 0.9352\n",
            "Epoch 35/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5196 - acc: 0.9453\n",
            "Epoch 00035: val_acc did not improve from 0.93521\n",
            "698/698 [==============================] - 829s 1s/step - loss: 0.5196 - acc: 0.9453 - val_loss: 0.6694 - val_acc: 0.9352\n",
            "Epoch 36/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5235 - acc: 0.9449\n",
            "Epoch 00036: val_acc improved from 0.93521 to 0.93581, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 833s 1s/step - loss: 0.5235 - acc: 0.9449 - val_loss: 0.6646 - val_acc: 0.9358\n",
            "Epoch 37/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5137 - acc: 0.9460\n",
            "Epoch 00037: val_acc improved from 0.93581 to 0.93658, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 841s 1s/step - loss: 0.5137 - acc: 0.9460 - val_loss: 0.6608 - val_acc: 0.9366\n",
            "Epoch 38/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.5071 - acc: 0.9467\n",
            "Epoch 00038: val_acc improved from 0.93658 to 0.93712, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 847s 1s/step - loss: 0.5071 - acc: 0.9467 - val_loss: 0.6538 - val_acc: 0.9371\n",
            "Epoch 39/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4985 - acc: 0.9475\n",
            "Epoch 00039: val_acc improved from 0.93712 to 0.93781, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 844s 1s/step - loss: 0.4985 - acc: 0.9475 - val_loss: 0.6515 - val_acc: 0.9378\n",
            "Epoch 40/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4927 - acc: 0.9482\n",
            "Epoch 00040: val_acc improved from 0.93781 to 0.93805, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 845s 1s/step - loss: 0.4927 - acc: 0.9482 - val_loss: 0.6502 - val_acc: 0.9380\n",
            "Epoch 41/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4886 - acc: 0.9489\n",
            "Epoch 00041: val_acc improved from 0.93805 to 0.93837, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 849s 1s/step - loss: 0.4886 - acc: 0.9489 - val_loss: 0.6463 - val_acc: 0.9384\n",
            "Epoch 42/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4860 - acc: 0.9492\n",
            "Epoch 00042: val_acc improved from 0.93837 to 0.93904, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 845s 1s/step - loss: 0.4860 - acc: 0.9492 - val_loss: 0.6393 - val_acc: 0.9390\n",
            "Epoch 43/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4807 - acc: 0.9497\n",
            "Epoch 00043: val_acc did not improve from 0.93904\n",
            "698/698 [==============================] - 841s 1s/step - loss: 0.4807 - acc: 0.9497 - val_loss: 0.6396 - val_acc: 0.9390\n",
            "Epoch 44/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4765 - acc: 0.9502\n",
            "Epoch 00044: val_acc improved from 0.93904 to 0.93949, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 844s 1s/step - loss: 0.4765 - acc: 0.9502 - val_loss: 0.6329 - val_acc: 0.9395\n",
            "Epoch 45/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4725 - acc: 0.9508\n",
            "Epoch 00045: val_acc improved from 0.93949 to 0.93953, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 843s 1s/step - loss: 0.4725 - acc: 0.9508 - val_loss: 0.6357 - val_acc: 0.9395\n",
            "Epoch 46/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4684 - acc: 0.9511\n",
            "Epoch 00046: val_acc improved from 0.93953 to 0.93994, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 844s 1s/step - loss: 0.4684 - acc: 0.9511 - val_loss: 0.6309 - val_acc: 0.9399\n",
            "Epoch 47/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4645 - acc: 0.9516\n",
            "Epoch 00047: val_acc improved from 0.93994 to 0.94031, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 843s 1s/step - loss: 0.4645 - acc: 0.9516 - val_loss: 0.6300 - val_acc: 0.9403\n",
            "Epoch 48/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4617 - acc: 0.9519\n",
            "Epoch 00048: val_acc improved from 0.94031 to 0.94043, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 848s 1s/step - loss: 0.4617 - acc: 0.9519 - val_loss: 0.6238 - val_acc: 0.9404\n",
            "Epoch 49/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4598 - acc: 0.9521\n",
            "Epoch 00049: val_acc improved from 0.94043 to 0.94089, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 847s 1s/step - loss: 0.4598 - acc: 0.9521 - val_loss: 0.6199 - val_acc: 0.9409\n",
            "Epoch 50/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4572 - acc: 0.9526\n",
            "Epoch 00050: val_acc did not improve from 0.94089\n",
            "698/698 [==============================] - 843s 1s/step - loss: 0.4572 - acc: 0.9526 - val_loss: 0.6201 - val_acc: 0.9407\n",
            "Epoch 51/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4552 - acc: 0.9528\n",
            "Epoch 00051: val_acc did not improve from 0.94089\n",
            "698/698 [==============================] - 840s 1s/step - loss: 0.4552 - acc: 0.9528 - val_loss: 0.6158 - val_acc: 0.9409\n",
            "Epoch 52/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4530 - acc: 0.9530\n",
            "Epoch 00052: val_acc improved from 0.94089 to 0.94144, saving model to ./seq2seq_news_title.h5\n",
            "698/698 [==============================] - 843s 1s/step - loss: 0.4530 - acc: 0.9530 - val_loss: 0.6173 - val_acc: 0.9414\n",
            "Epoch 53/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4510 - acc: 0.9532\n",
            "Epoch 00053: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 841s 1s/step - loss: 0.4510 - acc: 0.9532 - val_loss: 0.6162 - val_acc: 0.9409\n",
            "Epoch 54/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4498 - acc: 0.9535\n",
            "Epoch 00054: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 842s 1s/step - loss: 0.4498 - acc: 0.9535 - val_loss: 0.6110 - val_acc: 0.9410\n",
            "Epoch 55/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4474 - acc: 0.9537\n",
            "Epoch 00055: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 844s 1s/step - loss: 0.4474 - acc: 0.9537 - val_loss: 0.6109 - val_acc: 0.9411\n",
            "Epoch 56/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4453 - acc: 0.9540\n",
            "Epoch 00056: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 845s 1s/step - loss: 0.4453 - acc: 0.9540 - val_loss: 0.6117 - val_acc: 0.9412\n",
            "Epoch 57/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4437 - acc: 0.9541\n",
            "Epoch 00057: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 846s 1s/step - loss: 0.4437 - acc: 0.9541 - val_loss: 0.6051 - val_acc: 0.9406\n",
            "Epoch 58/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4425 - acc: 0.9542\n",
            "Epoch 00058: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 846s 1s/step - loss: 0.4425 - acc: 0.9542 - val_loss: 0.6093 - val_acc: 0.9412\n",
            "Epoch 59/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4409 - acc: 0.9544\n",
            "Epoch 00059: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 845s 1s/step - loss: 0.4409 - acc: 0.9544 - val_loss: 0.6058 - val_acc: 0.9413\n",
            "Epoch 60/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4400 - acc: 0.9545\n",
            "Epoch 00060: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 845s 1s/step - loss: 0.4400 - acc: 0.9545 - val_loss: 0.6083 - val_acc: 0.9414\n",
            "Epoch 61/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4396 - acc: 0.9546\n",
            "Epoch 00061: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 846s 1s/step - loss: 0.4396 - acc: 0.9546 - val_loss: 0.6079 - val_acc: 0.9412\n",
            "Epoch 62/100\n",
            "698/698 [==============================] - ETA: 0s - loss: 0.4391 - acc: 0.9547\n",
            "Epoch 00062: val_acc did not improve from 0.94144\n",
            "698/698 [==============================] - 846s 1s/step - loss: 0.4391 - acc: 0.9547 - val_loss: 0.6065 - val_acc: 0.9411\n",
            "Epoch 00062: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f93ca6a3278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLMsxJT8yIyt",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nb1Ska5yKQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, [encoder_outputs, forward_h_state, forward_c_state, backward_h_state, backward_c_state])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4L6aLKwyKAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_forward_h_state = Input(shape=(LSTM_unit,))\n",
        "encoder_forward_c_state = Input(shape=(LSTM_unit,))\n",
        "encoder_backward_h_state = Input(shape=(LSTM_unit,))\n",
        "encoder_backward_c_state = Input(shape=(LSTM_unit,))\n",
        "\n",
        "pd_decoder_outputs, pd_forward_h_state, pd_forward_c_state, pd_backward_h_state, pd_backward_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_forward_h_state, encoder_forward_c_state, encoder_backward_h_state, encoder_backward_c_state])\n",
        "\n",
        "# 어텐션\n",
        "pd_encoder_outputs = Input(shape=(encoder_input.shape[1], LSTM_unit*2))\n",
        "pd_attn_out, pd_attn_states = attn_layer([pd_encoder_outputs, pd_decoder_outputs])\n",
        "pd_decoder_concat = Concatenate()([pd_decoder_outputs, pd_attn_out])\n",
        "\n",
        "pd_decoder_softmax_outputs = decoder_dense(pd_decoder_concat)\n",
        "\n",
        "decoder_model = Model([decoder_inputs, pd_encoder_outputs, encoder_forward_h_state, encoder_forward_c_state, encoder_backward_h_state, encoder_backward_c_state], [pd_decoder_softmax_outputs, pd_forward_h_state, pd_forward_c_state, pd_backward_h_state, pd_backward_c_state])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If02WeQJy4Ny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "770caa05-371b-4e5e-c19b-c9737bcd0148"
      },
      "source": [
        "input_stc = input()\n",
        "preprocess_stc = input_stc.replace(\"\\n\",\" \").replace(\" +\", \" \").replace(\"[^\\w]\",\"\")\n",
        "token_stc = okt.morphs(preprocess_stc, stem=True)\n",
        "encode_stc = tokenizer_en.texts_to_sequences([token_stc])\n",
        "pad_stc = pad_sequences(encode_stc, maxlen=encoder_input.shape[1], padding=\"post\")\n",
        "\n",
        "en_out, for_en_hidden, for_en_cell, back_en_hidden, back_en_cell = encoder_model.predict(pad_stc)\n",
        "\n",
        "predicted_seq = np.zeros((1,1))\n",
        "predicted_seq[0,0] = de_to_index[\"<start>\"]\n",
        "\n",
        "decoded_stc = []\n",
        "\n",
        "while True:\n",
        "    output_words, for_h, for_c, back_h, back_c = decoder_model.predict([predicted_seq, en_out, for_en_hidden, for_en_cell, back_en_hidden, back_en_cell])\n",
        "\n",
        "    predicted_word = index_to_de[np.argmax(output_words[0,0])]\n",
        "\n",
        "    if predicted_word == \"<end>\":\n",
        "        break\n",
        "    \n",
        "    decoded_stc.append(predicted_word)\n",
        "    print(predicted_word)\n",
        "    predicted_seq = np.zeros((1,1))\n",
        "    predicted_seq[0,0] = np.argmax(output_words[0,0])\n",
        "\n",
        "    for_en_hidden = for_h\n",
        "    for_en_cell = for_c\n",
        "    back_en_hidden = back_h\n",
        "    back_en_cell = back_c\n",
        "\n",
        "print(' '.join(decoded_stc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "과학기술정보통신부는 '전문과학관 건립 사업' 대상 지역 후보지로 강원도와 울산광역시, 전라남도 등 3곳을 선정했다고 오늘(17일) 밝혔습니다.  과기정통부는 이들 후보지 3곳을 대상으로, 현장 조사를 거쳐 최종 건립 대상지를 선정할 예정입니다. 결과는 오는 31일 발표됩니다. 과기정통부는 지난 3월 전문과학관 건립을 신청한 강원, 경기, 경북, 경남, 서울, 인천, 울산, 충남, 전북, 전남 등 10곳을 대상으로 후보지를 물색해 왔습니다.전문과학관은 지역 균형 발전과 과학문화 향유 기획 확대를 위해 추진되는 사업으로, 건립에는 국비 2백45억 원과 지방비 105억 원이 투입됩니다.\n",
            "전체\n",
            "연구기관\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n",
            "창조경제\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-7ba89d671032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_en_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_en_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_en_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_en_cell\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpredicted_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_to_de\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUJdwZf4RYTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "5a0ddb2e-15a4-480a-87ab-d099ba5229b9"
      },
      "source": [
        "encoder_input_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31252,   364,  1641, ...,     0,     0,     0],\n",
              "       [ 5411,     9,    61, ...,     0,     0,     0],\n",
              "       [  787,  1520,   173, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [   91,   524,   173, ...,     0,     0,     0],\n",
              "       [ 1512,    15,   708, ...,     0,     0,     0],\n",
              "       [ 2408,  1864,  4363, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7qW_f-ph4R_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}